{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b854f4ee-3a3c-4273-8c32-9cbe4aa4546a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64811e1-9064-4578-9ab0-bef2d10afd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# pyarrow and feather\n",
    "import pyarrow.feather as feather\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import rpy2_arrow.pyarrow_rarrow as pyra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "933642a1-e811-4fdc-a613-26f675f22ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibaad\\.conda\\envs\\525_2022\\lib\\site-packages\\rpy2\\robjects\\packages.py:366: UserWarning: The symbol 'quartz' is not in this R namespace/package.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5976a30-5808-477f-abb2-cc4a464ca8a4",
   "metadata": {},
   "source": [
    "# 1. Teamwork Contract\n",
    "The teamwork contract for our team, group 7, can be found [here](https://docs.google.com/document/d/1u4e5Z5C-uwTTSvCEyOYy-I30Fb8OEPYM6frM0NBEVVc/edit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9aee01-4eb9-4a7b-8920-802d235f9199",
   "metadata": {},
   "source": [
    "# 2. Create repository and project structure\n",
    "The repository URL: https://github.com/UBC-MDS/DSCI525-Group7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e53d5d4-a952-4b38-84cf-7b96510045c4",
   "metadata": {},
   "source": [
    "# 3. Downloading the data\n",
    "\n",
    "Using Python **requests** Library\n",
    "\n",
    "We are using article id #14096681, which contains the data of **Daily rainfall over NSW, Australia.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c326b50-df61-4679-b95c-7c5e18cc9a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "article_id = 14096681  \n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"rainfall/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de6fe8-cef7-4184-94c6-82f29e2cfd42",
   "metadata": {},
   "source": [
    "Review the files within the article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e03159ea-764b-46fc-8a20-249e5529894b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 26579150,\n",
       "  'name': 'daily_rainfall_2014.png',\n",
       "  'size': 58863,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579150',\n",
       "  'supplied_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'computed_md5': 'fd32a2ffde300a31f8d63b1825d47e5e'},\n",
       " {'id': 26579171,\n",
       "  'name': 'environment.yml',\n",
       "  'size': 192,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579171',\n",
       "  'supplied_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'computed_md5': '060b2020017eed93a1ee7dd8c65b2f34'},\n",
       " {'id': 26586554,\n",
       "  'name': 'README.md',\n",
       "  'size': 5422,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26586554',\n",
       "  'supplied_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'computed_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c'},\n",
       " {'id': 26766812,\n",
       "  'name': 'data.zip',\n",
       "  'size': 814041183,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766812',\n",
       "  'supplied_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'computed_md5': 'b517383f76e77bd03755a63a8ff83ee9'},\n",
       " {'id': 26766815,\n",
       "  'name': 'get_data.py',\n",
       "  'size': 4113,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766815',\n",
       "  'supplied_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'computed_md5': '7829028495fd9dec9680ea013474afa6'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # this contains all the articles data, feel free to check it out\n",
    "files = data[\"files\"]             # this is just the data about the files, which is what we want\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e52d215-05c2-48a4-834b-4e1f71890473",
   "metadata": {},
   "source": [
    "# 3.1 Unzipping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c5cf54-861a-4e80-8a72-cdfdaca747ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6.81 s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "files_to_dl = [\"data.zip\"]  \n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a659d0f5-fbce-4e61-8c93-dba0e36e82a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(os.path.join(output_directory, \"data.zip\"), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62750636-4ddb-4e19-a4d2-bab89e561242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid switch - \"\".\n"
     ]
    }
   ],
   "source": [
    "%ls -ltr rainfall/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b56f5-8d99-4085-aa8f-bcc95b6a6c40",
   "metadata": {},
   "source": [
    "# Comparison of Performance on Different Machines\n",
    "\n",
    "The summary of all team members' time taken to unzip the data is recorded below. Each team member's Operating System, RAM, Processor and SSD are also recorded to check if they have any effect on the time taken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd7aa16-f118-4b18-b1a7-bdcadb5f505a",
   "metadata": {},
   "source": [
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time Taken |\n",
    "|-------------|------------------|-----|-----------|--------|------------|\n",
    "| Jessie | Windows 10 Education | 16GB | Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz 1.99 GHz | Yes | CPU times: total: 8.48s <br> Wall time: 1min 35s |\n",
    "| Adrianne | Windows 10 Pro | 16GB | Intel(R) Core(TM) i7-1165G7 @ 2.80GHz 2.80 GHz | Yes | CPU times: total: 6.23s <br> Wall time: 1min 7s |\n",
    "| Rada | Macbook Pro 2013 15\" | 16GB | 2.3 GHz Intel Core i7 | No | CPU times: total: 10.4 s<br>Wall time: 3min 5s |\n",
    "| Moid | Windows 11 Education | 12GB | 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz 1.38 GHz | Yes | CPU times: total: 6.81s <br> Wall time: 1min 31s |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6ba519-2c6d-4224-8531-2e7167833810",
   "metadata": {},
   "source": [
    "Macbook Pro took palpably longer than the rest for this process. Would be curious to review the reason."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96637ec-45ec-404a-831e-1c370d6a6439",
   "metadata": {},
   "source": [
    "# 4. Combining data CSVs\n",
    "\n",
    "- Combine data CSVs into a single CSV using pandas.\n",
    "\n",
    "- When combining the CSV files, add an extra column called \"model\" that identifies the model. Tip 1: you can get this column populated from the file name, eg: for file name \"SAM0-UNICON_daily_rainfall_NSW.csv\", the model name is SAM0-UNICON Tip 2: Remember how we added year when we combined airline CSVs. Tip 3: You can use regex generator.\n",
    "\n",
    "_Note: There is a file called observed_daily_rainfall_SYD.csv in the data folder that you downloaded. Make sure you exclude this file (programmatically or just take out that file from folder) before you combine CSVs. We will use this file in our next milestone._\n",
    "\n",
    "- Compare run times on different machines within your team and summarize your observations.\n",
    "Warning: Some of you might not be able to do it on your laptop. It's fine if you're unable to do it. Just make sure you discuss the reasons why you might not have been able to run this on your laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40676871-8964-4489-a541-0e84a7ac149c",
   "metadata": {},
   "source": [
    "Let's first view the data and the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf991be5-9a08-43ac-b12e-708d81bdc456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.7 s\n",
      "Wall time: 5.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_1 = pd.read_csv(output_directory+\"/MPI-ESM-1-2-HAM_daily_rainfall_NSW.csv\")\n",
    "df_2 = pd.read_csv(output_directory+\"/CMCC-CM2-SR5_daily_rainfall_NSW.csv\")\n",
    "df_3 = pd.read_csv(output_directory+\"/SAM0-UNICON_daily_rainfall_NSW.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e69142-a3fc-4b6f-81ad-b45a666263ef",
   "metadata": {},
   "source": [
    "Even loading three of the individual files is taking a little time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cd74e93-83bc-45bd-9376-135b045e5702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.244226e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.217326e-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time    lat_min    lat_max   lon_min   lon_max  \\\n",
       "0  1889-01-01 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "1  1889-01-02 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "\n",
       "   rain (mm/day)  \n",
       "0   4.244226e-13  \n",
       "1   4.217326e-13  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d56f6df-a1e0-494b-9c28-916ad97e95ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>0.000424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>0.006158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time    lat_min   lat_max  lon_min  lon_max  rain (mm/day)\n",
       "0  1889-01-01 12:00:00 -35.811518 -34.86911  140.625  141.875       0.000424\n",
       "1  1889-01-02 12:00:00 -35.811518 -34.86911  140.625  141.875       0.006158"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7be8e1b4-58a5-4a0d-9044-9d358566f661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>3.045650e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>3.572392e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time    lat_min   lat_max  lon_min  lon_max  rain (mm/day)\n",
       "0  1889-01-01 12:00:00 -35.811518 -34.86911  140.625  141.875   3.045650e-13\n",
       "1  1889-01-02 12:00:00 -35.811518 -34.86911  140.625  141.875   3.572392e-04"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f49d1b94-dccd-4427-a814-081554396930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3541151</th>\n",
       "      <td>2014-12-30 12:00:00</td>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>8.541592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541152</th>\n",
       "      <td>2014-12-31 12:00:00</td>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>68.117489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time    lat_min   lat_max  lon_min  lon_max  \\\n",
       "3541151  2014-12-30 12:00:00 -30.157068 -29.21466  153.125  154.375   \n",
       "3541152  2014-12-31 12:00:00 -30.157068 -29.21466  153.125  154.375   \n",
       "\n",
       "         rain (mm/day)  \n",
       "3541151       8.541592  \n",
       "3541152      68.117489  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f9e0468-45da-419a-94dc-f0b576a9ed11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6min 34s\n",
      "Wall time: 6min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "files = glob.glob('./rainfall/*NSW.csv')\n",
    "df = pd.concat((pd.read_csv(file, index_col=0)\n",
    "                .assign(model=re.findall(r'/([^_]*)', file)[0])\n",
    "                for file in files)\n",
    "              )\n",
    "df.to_csv(\"rainfall/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c64f81-752f-4c2d-80bc-a3b224980550",
   "metadata": {},
   "source": [
    "**For Windows user:**   \n",
    "Windows users will run into an index error when running the code above to combine the CSVs.   \n",
    "This can be solved by adding a ./ to the filename as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18b7f1d9-b89d-4ae3-b3d4-6460016748a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3622.16 MiB, increment: 0.72 MiB\n",
      "CPU times: total: 7min 1s\n",
      "Wall time: 7min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "files = glob.glob('./rainfall/*NSW.csv')\n",
    "df = pd.concat((pd.read_csv(file, index_col=0)\n",
    "                .assign(model=file.strip('./rainfall\\\\').split('_')[0])\n",
    "                for file in files)\n",
    "              )\n",
    "df.to_csv(\"rainfall/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd16d5f7-77a6-4bcf-9cd7-98505b2a983c",
   "metadata": {},
   "source": [
    "Wow, this felt like an eternity!\n",
    "\n",
    "Let's take a look at the combined file, see if head and tail are as we expect them to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bab6c92a-e605-4b11-b7d6-472e73a691cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1889-01-01 12:00:00</th>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>3.293256e-13</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-02 12:00:00</th>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-03 12:00:00</th>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-04 12:00:00</th>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-05 12:00:00</th>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>1.047658e-02</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     lat_min  lat_max  lon_min  lon_max  rain (mm/day)  \\\n",
       "time                                                                     \n",
       "1889-01-01 12:00:00   -36.25    -35.0  140.625    142.5   3.293256e-13   \n",
       "1889-01-02 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "1889-01-03 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "1889-01-04 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "1889-01-05 12:00:00   -36.25    -35.0  140.625    142.5   1.047658e-02   \n",
       "\n",
       "                          model  \n",
       "time                             \n",
       "1889-01-01 12:00:00  ACCESS-CM2  \n",
       "1889-01-02 12:00:00  ACCESS-CM2  \n",
       "1889-01-03 12:00:00  ACCESS-CM2  \n",
       "1889-01-04 12:00:00  ACCESS-CM2  \n",
       "1889-01-05 12:00:00  ACCESS-CM2  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2635431e-cbf1-4056-8638-4aa81ccc4987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-27 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>0.554375</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-28 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>7.028577</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-29 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>0.234757</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>2.097459</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>0.548421</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       lat_min   lat_max  lon_min  lon_max  rain (mm/day)  \\\n",
       "time                                                                        \n",
       "2014-12-27 12:00:00 -30.157068 -29.21466  153.125  154.375       0.554375   \n",
       "2014-12-28 12:00:00 -30.157068 -29.21466  153.125  154.375       7.028577   \n",
       "2014-12-29 12:00:00 -30.157068 -29.21466  153.125  154.375       0.234757   \n",
       "2014-12-30 12:00:00 -30.157068 -29.21466  153.125  154.375       2.097459   \n",
       "2014-12-31 12:00:00 -30.157068 -29.21466  153.125  154.375       0.548421   \n",
       "\n",
       "                       model  \n",
       "time                          \n",
       "2014-12-27 12:00:00  TaiESM1  \n",
       "2014-12-28 12:00:00  TaiESM1  \n",
       "2014-12-29 12:00:00  TaiESM1  \n",
       "2014-12-30 12:00:00  TaiESM1  \n",
       "2014-12-31 12:00:00  TaiESM1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41611d5-c775-43c5-9422-4df1ddbd0333",
   "metadata": {},
   "source": [
    "## Comparison of Performance on Different Machines\n",
    "\n",
    "The summary of all team members' time taken to combine the CSV's files is recorded below. Each team member's Operating System, RAM, Processor and SSD are also recorded to check if they have any effect on the time taken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4cc9f7-345e-4c9c-90b5-ecd922fea905",
   "metadata": {},
   "source": [
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time Taken |\n",
    "|-------------|------------------|-----|-----------|--------|------------|\n",
    "| Jessie | Windows 10 Education | 16GB | Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz 1.99 GHz | Yes | peak memory: 800.19 MiB <br> increment: 0.00 MiB <br> CPU times: total: 8min 33s <br> Wall time: 8min 40s |\n",
    "| Adrianne | Windows 10 Pro | 16GB | Intel(R) Core(TM) i7-1165G7 @ 2.80GHz 2.80 GHz | Yes | peak memory: 120.25 MiB <br> increment: 0.30 MiB <br> CPU times: total: 7min 26s <br> Wall time: 7min 31s |\n",
    "| Rada | Macbook Pro 2013 15\" | 16GB | 2.3 GHz Intel Core i7 | No | peak memory: 3939.19 MiB <br> increment: 0.10 MiB <br> CPU times: user 7min 14s, sys: 21.5 s, total: 7min 36s  <br> Wall time: 7min 47s |\n",
    "| Moid | Windows 11 Education | 12GB | 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz 1.38 GHz | Yes | peak memory: 3622.16 MiB <br> increment: 0.72 MiB <br> CPU times: total: 7min 1s <br> Wall time: 7min 5s |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7940f07a-90db-4d37-b0e2-b81309929f48",
   "metadata": {},
   "source": [
    "Combining process is long in general, but quite consistent. Interesting to note the peak memory spike on Macbook Pro machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b7fbb1-e064-4862-bfd7-366e4810b3e3",
   "metadata": {},
   "source": [
    "# 5. Load the combined CSV to memory and perform a simple EDA\n",
    "\n",
    "1. Investigate at least two of the following approaches to reduce memory usage while performing the EDA (e.g., value_counts).\n",
    "\n",
    "- Changing dtype of your data\n",
    "- Load just columns what we want\n",
    "- Loading in chunks\n",
    "- Dask\n",
    "\n",
    "2. Compare run times on different machines within your team and summarize your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01927b22-3abf-4ddd-b972-1391b3067bb1",
   "metadata": {},
   "source": [
    "**The EDA will be to use value_counts() to count the number of data points that came from each .csv file, as recorded in the model column of combined_data.csv.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16642faa-44e6-4a8b-bb6e-2aafe730d977",
   "metadata": {},
   "source": [
    "### 5.1 Load the Entire Dataframe to Memory Using Pandas (Baseline for Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b38fd63-c051-4f6a-9a54-ba7a66b7185a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "TaiESM1             3541230\n",
      "NorESM2-MM          3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "SAM0-UNICON         3541153\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "MRI-ESM2-0          3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM5-0           1609650\n",
      "INM-CM4-8           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "Name: model, dtype: int64\n",
      "peak memory: 8342.65 MiB, increment: 7312.43 MiB\n",
      "CPU times: total: 1min 1s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "df_pandas = pd.read_csv(\"rainfall/combined_data.csv\")\n",
    "print(df_pandas[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382ea113-f801-4c4c-ab36-f979c902ca79",
   "metadata": {},
   "source": [
    "**Observations**\n",
    ">Our baseline approach is to use Pandas to load the entire data to memory. The above code loads the combined_data.csv to memory and performs a simple EDA to calculate counts of values in the \"model\" column. We see that the peak memory is 9060 MiB and the CPU and wall time is 1min 31s. We will explore some other approaches to see if we can reduce the time and memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e74ea-8f2a-4748-ab28-9e704e8d89b6",
   "metadata": {},
   "source": [
    "### 5.2 Changing dtypes of data:\n",
    "\n",
    "- We will attempt to change time column from datetime to date\n",
    "- We will attempt to read the numerical columns using float32 format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c78aef6-e83a-44d2-9619-75d946e92a58",
   "metadata": {},
   "source": [
    "Memory comparison for format changes adapted from Lecture notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9bb9533-b591-4e30-9f96-12c7ae5a4a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage with float64: 2998.46 MB\n",
      "Memory usage with float32: 1749.10 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory usage with float64: {df[['lat_min','lat_max', 'lon_min', 'lon_max', 'rain (mm/day)']].memory_usage().sum() / 1e6:.2f} MB\")\n",
    "print(f\"Memory usage with float32: {df[['lat_min','lat_max', 'lon_min', 'lon_max', 'rain (mm/day)']].astype('float32', errors='ignore').memory_usage().sum() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8666e81b-c151-4de1-be4a-8f05e419da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_float32 = df.copy()\n",
    "df_float32[['lat_min','lat_max','lon_min', 'lon_max', 'rain (mm/day)']].astype('float32')\n",
    "\n",
    "#saving the dataframe of float32 to file\n",
    "df_float32.to_csv(\"rainfall/combined_data_float32.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e243f1be-cee8-48a8-a455-bc9c051f4a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "TaiESM1             3541230\n",
      "NorESM2-MM          3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "SAM0-UNICON         3541153\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "MRI-ESM2-0          3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM5-0           1609650\n",
      "INM-CM4-8           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "Name: model, dtype: int64\n",
      "peak memory: 9341.97 MiB, increment: 2808.60 MiB\n",
      "CPU times: total: 1min 4s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "#loading the float32 dataframe to memory and perform a simple EDA for value counts of model column\n",
    "df_float32 = pd.read_csv(\"rainfall/combined_data_float32.csv\")\n",
    "print(df_float32[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae86de81-2d49-49c3-817c-41a28ec5a3f2",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "> When we changed the data type from float64 to float32 the memory usage reduced by nearly half. This is because float32 is stored as a 32-bit number, while float64 is stored as 64-bit number, which is twice as much memory as float32. With the EDA, we see that after converting dtypes to float 32, the peak memory usage decreased and the increment memory was halved. Both the CPU and wall time also decreased. Changing the dtype is effective in reducing the time and memory required to load data, and should be used when we have a large amount of data that does not require very high precision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f5c3d-f616-4cc2-a908-50aa9b72055e",
   "metadata": {},
   "source": [
    "### 5.3 Dask:\n",
    "\n",
    "- We will attempt to read dataframe using dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8bdeaff-ec09-4819-a7c2-db4deeda9e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "TaiESM1             3541230\n",
      "NorESM2-MM          3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "SAM0-UNICON         3541153\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "MRI-ESM2-0          3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM5-0           1609650\n",
      "INM-CM4-8           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "Name: model, dtype: int64\n",
      "peak memory: 3671.34 MiB, increment: 1263.45 MiB\n",
      "CPU times: total: 1min 6s\n",
      "Wall time: 23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "# Dask\n",
    "df_dask = dd.read_csv('rainfall/combined_data.csv')\n",
    "print(df_dask[\"model\"].value_counts().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432e8485-ede7-4179-b7b2-3fee5b49fa00",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "> Using a Dask dataframe is much faster and lighter on memory. Compared to loading the csv to pandas data frame, when we load the csv file to dask, the peak memory, increment memory, and wall time all reduced significantly when calling the value_counts() function. This is likely because dask partitioned the dataframe based on row index and did the calculation in parallel to improve the efficiency. Thus, for large-scale data calculation, we could use dask instead of pandas to improve the code efficiency with minimal syntax change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bec6a11-a1c7-47b4-a86f-a44603bd07f2",
   "metadata": {},
   "source": [
    "### 5.4 Loading in Chunks:\n",
    "\n",
    "- We will attempt to read dataframe in chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c07eb0-bf10-4175-80c0-744af2d814f8",
   "metadata": {},
   "source": [
    "#### Chunksize = 10 million:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "172e7a9f-6edb-424b-8e66-e6f0389336c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "AWI-ESM-1-1-LR       966420\n",
      "BCC-CSM2-MR         3035340\n",
      "BCC-ESM1             551880\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "CanESM5              551880\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "FGOALS-f3-L         3219300\n",
      "FGOALS-g3           1287720\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "MIROC6              2070900\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-HR       5154240\n",
      "MPI-ESM1-2-LR        966420\n",
      "MRI-ESM2-0          3037320\n",
      "NESM3                966420\n",
      "NorESM2-LM           919800\n",
      "NorESM2-MM          3541230\n",
      "SAM0-UNICON         3541153\n",
      "TaiESM1             3541230\n",
      "dtype: int32\n",
      "peak memory: 4878.68 MiB, increment: 2461.23 MiB\n",
      "CPU times: total: 59.6 s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "counts = pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(\"rainfall/combined_data.csv\", chunksize=10_000_000):\n",
    "    counts = counts.add(chunk[\"model\"].value_counts(), fill_value=0)\n",
    "print(counts.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b3342-3ebc-4e5a-a0ad-63b229547c75",
   "metadata": {},
   "source": [
    "#### Chunksize = 1 million:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a37c04e-9ffb-4e8a-80e2-0212bf7b391c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "AWI-ESM-1-1-LR       966420\n",
      "BCC-CSM2-MR         3035340\n",
      "BCC-ESM1             551880\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "CanESM5              551880\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "FGOALS-f3-L         3219300\n",
      "FGOALS-g3           1287720\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "MIROC6              2070900\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-HR       5154240\n",
      "MPI-ESM1-2-LR        966420\n",
      "MRI-ESM2-0          3037320\n",
      "NESM3                966420\n",
      "NorESM2-LM           919800\n",
      "NorESM2-MM          3541230\n",
      "SAM0-UNICON         3541153\n",
      "TaiESM1             3541230\n",
      "dtype: int32\n",
      "peak memory: 2723.29 MiB, increment: 93.77 MiB\n",
      "CPU times: total: 1min\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "counts = pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(\"rainfall/combined_data.csv\", chunksize=1_000_000):\n",
    "    counts = counts.add(chunk[\"model\"].value_counts(), fill_value=0)\n",
    "print(counts.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a142457-13db-45a4-9e49-26533081af6b",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "> When loading the data in chunks, the peak memory is significantly lower than that without using chunking method. We can see that loading in 10 million per chunk requires nearly 6800 MiB in peak memory usage, which is less than using Pandas to load all at once. Loading in 1 million per chunk requires only 3740 MiB in peak memory usage. The increment memory is almost 10 times less than using Pandas. This is significantly more efficient than using Pandas. However, we also notice that the CPU and wall time remains roughly the same in all these approaches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ca15d3-ce53-4422-9e26-7b505275ffe7",
   "metadata": {},
   "source": [
    "### 5.5 Selecting columns:\n",
    "\n",
    "Since we only want the model for EDA, we will import just the model column. This is faster and uses less memory than loading the whole dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c559aba-0717-48f7-bc1f-81ae8c4c0806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3431.61 MiB, increment: 955.93 MiB\n",
      "CPU times: total: 32 s\n",
      "Wall time: 35.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df = pd.read_csv(\"rainfall/combined_data.csv\", \n",
    "                 usecols = [\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f323be2a-c344-4b9b-86c0-6b5ffd7b5f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2957.45 MiB, increment: 1.23 MiB\n",
      "CPU times: total: 3.11 s\n",
      "Wall time: 3.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df[\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c24e81-a7da-478f-bf35-987c6cf57509",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    ">Running value_counts takes the same time as it did using the entire data set, probably because it has to iterate through the same number of rows. However, this should still be done whenever possible because it reduces memory required and speeds up loading data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f9666a",
   "metadata": {},
   "source": [
    "**Here is a comparison of different machines on two approaches - changing data type and using Dask:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f1f477",
   "metadata": {},
   "source": [
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time Taken (changing dtype to float32) | Time Taken (Dask) |\n",
    "|-------------|------------------|-----|-----------|--------|----------------------------------------|-------------------|\n",
    "| Jessie | Windows 10 Education | 16GB | Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz 1.99 GHz | Yes | peak memory: 8487.61 MiB, increment: 2461.12 MiB <br> CPU times: total: 1min 44s <br> Wall time: 1min 46s | peak memory: 4749.06 MiB, increment: 1255.98 MiB <br> CPU times: total: 1min 8s <br> Wall time: 23.5s |\n",
    "| Adrianne | Windows 10 Pro | 16GB | Intel(R) Core(TM) i7-1165G7 @ 2.80GHz 2.80 GHz | Yes | peak memory: 13214.80 MiB, increment: 9233.91 MiB <br> CPU times: total: 55.4s <br> Wall time: 57s | peak memory: 4240.98 MiB, increment: 1255.65 MiB <br> CPU times: total: 57.2s <br> Wall time: 20.6s |\n",
    "| Rada | Macbook Pro 2013 15\" | 16GB | 2.3 GHz Intel Core i7 | No | peak memory: 4715.13 MiB, increment: 1308.29 MiB <br> CPU times: user 1min 9s, sys: 24.7 s, total: 1min 34s <br> Wall time: 1min 43s | peak memory: 3904.75 MiB, increment: 1306.16 MiB <br> CPU times: user 49.2 s, sys: 13.4 s, total: 1min 2s <br> Wall time: 23.2s |\n",
    "| Moid | Windows 11 Education | 12GB | 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz 1.38 GHz | Yes | peak memory: 9341.97 MiB, increment: 2808.60 MiB <br> CPU times: total: 1min 4s <br> Wall time: 1min 8s | peak memory: 3671.34 MiB, increment: 1263.45 MiB <br> CPU times: total: 1min 6s <br> Wall time: 23s |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63006133",
   "metadata": {},
   "source": [
    "### 5.6 Aggregation & Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbf8f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda = df.copy()\n",
    "df_eda = df_eda.reset_index()\n",
    "df_eda.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0033a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df_eda['year'] = pd.DatetimeIndex(df_eda['time']).year\n",
    "df_eda['month'] = pd.DatetimeIndex(df_eda['time']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667c9ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4420be4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df_eda = df_eda[['model','year','rain (mm/day)']]\n",
    "df_eda = df_eda.groupby(['model', 'year']).agg('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e7c76d",
   "metadata": {},
   "source": [
    "**<center>Extracting Month and Year from Date, and Aggregation Times Comparison</center>**\n",
    "\n",
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time Taken (Extracting) | Time Taken (Aggregation) |\n",
    "|-------------|------------------|-----|-----------|--------|-------------------------|--------------------------|\n",
    "| Jessie      | Windows 10 Education |  16GB      |   Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz   1.99 GHz        |   Yes    |    | \n",
    "| Adrianne    | Windows 10 Pro       |  16GB     | Intel(R) Core(TM) i7-1165G7 @ 2.80GHz 2.80 GHz                |   Yes     |   |\n",
    "| Rada        | Macbook Pro 2013 15\" |  16GB     | 2.3 GHz Intel Core i7                                         |   No      |  27.3 s  |   12.2s\n",
    "| Moid        |                      |           |                                                                |           |           |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c72be37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda = df_eda.reset_index()\n",
    "df_eda.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b96ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "plot = alt.Chart(df_eda).mark_line().encode(\n",
    "    x='year',\n",
    "    y='rain (mm/day)',\n",
    "    color='model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d74f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "plot2 = alt.Chart(df_eda).mark_bar().encode(\n",
    "    x='rain (mm/day):Q',\n",
    "    y=alt.Y('model:N', sort='-x')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a72bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60edffd8",
   "metadata": {},
   "source": [
    "**<center>Plotting Times Comparison</center>**\n",
    "\n",
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time Taken (Plot1) | Time Taken (Plot2) |\n",
    "|-------------|------------------|-----|-----------|--------|--------------------|--------------------|\n",
    "| Jessie      | Windows 10 Education |  16GB      |   Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz   1.99 GHz        |   Yes    |    | \n",
    "| Adrianne    | Windows 10 Pro       |  16GB     | Intel(R) Core(TM) i7-1165G7 @ 2.80GHz 2.80 GHz                |   Yes     |   |\n",
    "| Rada        | Macbook Pro 2013 15\" |  16GB     | 2.3 GHz Intel Core i7                                         |   No      |  1.43s  |   1.82s\n",
    "| Moid        |                      |           |                                                                |           |           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad2ac68-c355-45c4-a42f-456082879e82",
   "metadata": {},
   "source": [
    "# 6. Perform a simple EDA in R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d556d66-1dd5-4594-b1c8-3bcf015c9c52",
   "metadata": {},
   "source": [
    "To perform EDA in R, we first need to transfer the dataframe from Python to R.\n",
    "In this section, we will pass data from python to R in various ways and asses each method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4b97ee-224d-4711-81a6-6d224ca8ea26",
   "metadata": {},
   "source": [
    "## 6.1 Store the Data in Different Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d22021-6d55-41b9-93c6-6b3434250e4c",
   "metadata": {},
   "source": [
    "### 6.1.1 Arrow file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1791571a-601c-4c65-80da-f4f53109350d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "#Loading library\n",
    "library(arrow);\n",
    "library(dplyr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ae424c3-dabe-45cf-9c61-fe4fe8090c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 6806.23 MiB, increment: 3689.79 MiB\n",
      "CPU times: total: 31.8 s\n",
      "Wall time: 30.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "dataset = ds.dataset(\"rainfall/combined_data.csv\", format=\"csv\")\n",
    "\n",
    "table = dataset.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d002a84-b8c0-470f-8cbc-4346c09aaffe",
   "metadata": {},
   "source": [
    "### 6.1.2 Feather format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cef5510f-b285-4951-9769-8a97e70a732e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.44 s\n",
      "Wall time: 2.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "feather.write_feather(table, 'rainfall/combined_data.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdd7906-6bce-4341-86e9-cc4c5d8829e1",
   "metadata": {},
   "source": [
    "Evidently, feather format comes with over 3x Wall time improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796ee1cc-5937-4896-8814-c698bcf9a5f2",
   "metadata": {},
   "source": [
    "### 6.1.3 Parquet format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa622966-5564-423e-be5e-707217d6ceb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.6 s\n",
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## writing as a single parquet \n",
    "pq.write_table(table, 'rainfall/combined_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc188151-37fd-41b1-be87-af95099f6da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 52.6 s\n",
      "Wall time: 44.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## writing as a partitioned parquet \n",
    "pq.write_to_dataset(table, 'rainfall/combined_data_partitioned.parquet',partition_cols=['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff29c01a-417e-4d25-b196-bfdda24e996d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.7G\trainfall/combined_data.csv\n",
      "1.1G\trainfall/combined_data.feather\n",
      "542M\trainfall/combined_data.parquet\n",
      "1.1G\trainfall/combined_data_partitioned.parquet\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# Check the size of different format\n",
    "du -sh rainfall/combined_data.csv\n",
    "du -sh rainfall/combined_data.feather\n",
    "du -sh rainfall/combined_data.parquet\n",
    "du -sh rainfall/combined_data_partitioned.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd0a49f-fbcb-4646-bb6d-b9e53e234537",
   "metadata": {},
   "source": [
    ">We can see that both Feather and Parquet have reduced the file size significantly. The wall time taken for feather and single parquet was much less than Arrow. Partitioned parquet took similar wall time as Arrow but it significantly reduced the file size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d620597d-5093-4c5d-9895-9bab9266d5fb",
   "metadata": {},
   "source": [
    "## 6.2 Transfer the Data in Different Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2e2f6f-dbba-43b1-bcb3-7ae12143d504",
   "metadata": {},
   "source": [
    "### 6.2.1 Pandas Exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eebae683-f571-4708-9401-61e628c46c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 8688.69 MiB, increment: 8356.05 MiB\n",
      "CPU times: total: 1min\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "#simple pandas: read the entire dataset into memory\n",
    "df = pd.read_csv(\"rainfall/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba032d9e-3269-4101-a14c-ce078a8669d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Error: cons memory exhausted (limit reached?)\n",
      "\n",
      "R[write to console]: Error: no more error handlers available (recursive errors?); invoking 'abort' restart\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R -i df\n",
    "start_time <- Sys.time()\n",
    "library(dplyr)\n",
    "# print(class(df))\n",
    "result <- df |> count(model)\n",
    "#print(result)\n",
    "end_time <- Sys.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fa6945-4694-4e20-9a7d-1af44571a4e3",
   "metadata": {},
   "source": [
    "### 6.2.2 Arrow Exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2571cb4-591b-4193-8045-cc417f952035",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "dataset = ds.dataset(\"rainfall/combined_data.csv\", format=\"csv\")\n",
    "table = dataset.to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e1e2c5-1b37-4672-bce9-2dcd5235e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "## Here we are converting arrow table so it can be passed to R\n",
    "r_table = pyra.converter.py2rpy(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31674021-c79c-4592-acb7-1af67a2e1361",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R -i r_table\n",
    "# Pass r_table from python\n",
    "\n",
    "start_time <- Sys.time()\n",
    "library(dplyr)\n",
    "counts <- r_table %>% collect() %>% count(model)\n",
    "end_time <- Sys.time()\n",
    "\n",
    "print(counts)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca4a476-55b9-4baa-9606-03f42fccac6a",
   "metadata": {},
   "source": [
    "### 6.2.3 Feather File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d04fcff-5bb6-491e-8534-523d7007818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "library(arrow)\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_feather(\"rainfall/combined_data.feather\")\n",
    "print(class(r_table))\n",
    "library(dplyr)\n",
    "result <- r_table %>% count(model) \n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb8ff2b-fab0-4cdb-890c-dc3112349d0c",
   "metadata": {},
   "source": [
    "### 6.2.4 Parquet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151b0d7-28d6-4303-9fad-c92ee8b46050",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "library(arrow)\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_parquet(\"rainfall/combined_data.parquet\")\n",
    "print(class(r_table))\n",
    "library(dplyr)\n",
    "result <- r_table %>% count(model)\n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3684fea6",
   "metadata": {},
   "source": [
    "### 6.3 Aggregation & Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c91567",
   "metadata": {},
   "source": [
    "Rename the column because it's easier to work that way in R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b5b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "r_table <- r_table %>% \n",
    "  rename(\n",
    "    rain = `rain (mm/day)`,\n",
    "    )\n",
    "start_time <- Sys.time()\n",
    "glimpse(r_table)\n",
    "end_time <- Sys.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e10a3b4",
   "metadata": {},
   "source": [
    "**Aggregate by Model only:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f88185",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "start_time <- Sys.time()\n",
    "summ_rain <- r_table %>% \n",
    "  group_by(model) %>%\n",
    "  summarise(mean_rain = mean(rain, na.rm = TRUE))\n",
    "end_time <- Sys.time()\n",
    "print(end_time - start_time)\n",
    "summ_rain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c800b0f",
   "metadata": {},
   "source": [
    "**Extract Month and Year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d602280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "library(lubridate)\n",
    "start_time <- Sys.time()\n",
    "year_month_table <- r_table %>% \n",
    "  mutate(year = year(time), month = month(time))\n",
    "end_time <- Sys.time()\n",
    "print(end_time - start_time)\n",
    "year_month_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8a1943",
   "metadata": {},
   "source": [
    "**Aggregated by Model and by Year:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "start_time <- Sys.time()\n",
    "summ_rain_2 <- year_month_table %>% \n",
    "  group_by(model, year, month) %>%\n",
    "  summarise(mean_rain = mean(rain, na.rm = TRUE))\n",
    "end_time <- Sys.time()\n",
    "print(end_time - start_time)\n",
    "summ_rain_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center>Extracting Month and Year from Date, and Aggregation Times Comparison</center>**\n",
    "\n",
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time Taken (Extracting) | Time Taken (Aggregation) |\n",
    "|-------------|------------------|-----|-----------|--------|-------------------------|--------------------------|\n",
    "| Jessie      | Windows 10 Education |  16GB      |   Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz   1.99 GHz        |   Yes    |    | \n",
    "| Adrianne    | Windows 10 Pro       |  16GB     | Intel(R) Core(TM) i7-1165G7 @ 2.80GHz 2.80 GHz                |   Yes     |   |\n",
    "| Rada        | Macbook Pro 2013 15\" |  16GB     | 2.3 GHz Intel Core i7                                         |   No      |  53.2 s  |   5.57s\n",
    "| Moid        |                      |           |                                                                |           |           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f0b32b",
   "metadata": {},
   "source": [
    "# SIMPLE GGPLOT HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a698807-c796-4212-8a99-23f6252f9eda",
   "metadata": {},
   "source": [
    "### Observations Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295d73d4-1ab3-4cb1-9663-5c6683eb98af",
   "metadata": {},
   "source": [
    "### File manipulation:  \n",
    "\n",
    "Downloading and unzipping the rainfall file took 6-11sec, with Windows machines fairing better than the Macbook.\n",
    "\n",
    "Combining the data by simple concatenation took about 7-8min. Windows 10 Edu machine took the longest, but Macbook pro had a scary high peak memory at about 1/4 of its total RAM. \n",
    "\n",
    "### Loading Data into R:\n",
    "\n",
    "We attempted several methods of loading the data into R, after previous work in pandas.   \n",
    "Loading only the columns we needed reduced loading times from raw of a bit over 1min to ~5sec. Loading using more suited memory-smart data types of float32 instead of float64 cut loading time\n",
    "\n",
    "**Arrow** exchange ~26, **Feather** loading ~8sec, **Parquet** ~11sec and **partitioned Parquet** which comes with some more optimization ~35sec.   \n",
    "And this is for a very large file with upwards of 62 million observations. Parquet is clearly a very good tool for loading the data.\n",
    "\n",
    "### EDA Comparisons\n",
    "\n",
    "For value counts EDA, raw **Pandas** took a very long time, upwards of 40 minutes for each of us.   \n",
    "This baseline looked intimidating. Fortunately, every alternative method improved the processing time significantly.   \n",
    "Different file loading techniques resulted in various time savings for the purposes of simple EDA computing value counts.   \n",
    "When loaded with **Arrow**, counting took ~53sec, with **Feather** ~20sec, with **Paraquet** ~10sec. Again, **Parquet** is proving to be a good tool for this kind of processing.\n",
    "\n",
    "For the extraction of year/month from date, times varied a lot based on the run, but overall Pandas took ~12sec and R took ~40sec.\n",
    "For the simple aggergation process, Pandas took ~6-10sec, and R took ~3-5sec to perform the same operation.\n",
    "Plotting process was simple and fast despite once the data was aggregated. Of course, plotting usually requires aggregation in the first place: it's rare that the user will be able to make sense of millions of data points of non-aggregated data. So really, the aggregation times are more important to quantify here, because it is unlikely that plotting of millions of points will ever come up in practice.\n",
    "\n",
    "\n",
    "### Machine Comparison Overall: \n",
    "\n",
    "In general, we didn't have a particularly wide variety of machine: each of us are on a 16GB RAM and Intel core.   \n",
    "We did have both Macbook and Windows machines to test the results.   \n",
    "It appears that the times are fairly consistent between operating systems.\n",
    "In fact, while we only recorded final times and memory usages for each step per laptop, rerunning the notebook several times resulted in similar variation in times and memory usage to what we got from using different laptops.   \n",
    "However, for most of the processes, Macbook machine was performing worse than others. A lot more tests on similar computers would need to be performed to get meaningful performance comparison because the Macbook is very old (2013) so besides the components of the build, wear and tear could affect the process timing"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f25c1b085bda671884cb3d2c565b233d1145a4f72639fa756796e207cd4b76ec"
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-525_2022]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
