{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b854f4ee-3a3c-4273-8c32-9cbe4aa4546a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64811e1-9064-4578-9ab0-bef2d10afd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# pyarrow and feather\n",
    "import pyarrow.feather as feather\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import rpy2_arrow.pyarrow_rarrow as pyra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933642a1-e811-4fdc-a613-26f675f22ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5976a30-5808-477f-abb2-cc4a464ca8a4",
   "metadata": {},
   "source": [
    "# 1. Teamwork Contract\n",
    "The teamwork contract for our team, group 7, can be found [here](https://docs.google.com/document/d/1u4e5Z5C-uwTTSvCEyOYy-I30Fb8OEPYM6frM0NBEVVc/edit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9aee01-4eb9-4a7b-8920-802d235f9199",
   "metadata": {},
   "source": [
    "# 2. Create repository and project structure\n",
    "The repository URL: https://github.com/UBC-MDS/DSCI525-Group7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e53d5d4-a952-4b38-84cf-7b96510045c4",
   "metadata": {},
   "source": [
    "# 3. Downloading the data\n",
    "\n",
    "Using Python **requests** Library\n",
    "\n",
    "We are using article id #14096681, which contains the data of **Daily rainfall over NSW, Australia.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c326b50-df61-4679-b95c-7c5e18cc9a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "article_id = 14096681  \n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"rainfall/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de6fe8-cef7-4184-94c6-82f29e2cfd42",
   "metadata": {},
   "source": [
    "Review the files within the article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03159ea-764b-46fc-8a20-249e5529894b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # this contains all the articles data, feel free to check it out\n",
    "files = data[\"files\"]             # this is just the data about the files, which is what we want\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e52d215-05c2-48a4-834b-4e1f71890473",
   "metadata": {},
   "source": [
    "# 3.1 Unzipping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c5cf54-861a-4e80-8a72-cdfdaca747ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "files_to_dl = [\"data.zip\"]  \n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a659d0f5-fbce-4e61-8c93-dba0e36e82a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(os.path.join(output_directory, \"data.zip\"), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62750636-4ddb-4e19-a4d2-bab89e561242",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls -ltr rainfall/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b56f5-8d99-4085-aa8f-bcc95b6a6c40",
   "metadata": {},
   "source": [
    "# Comparison of Performance on Different Machines\n",
    "\n",
    "The summary of all team members' time taken to unzip the data is recorded below. Each team member's Operating System, RAM, Processor and SSD are also recorded to check if they have any effect on the time taken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd7aa16-f118-4b18-b1a7-bdcadb5f505a",
   "metadata": {},
   "source": [
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time Taken |\n",
    "|-------------|------------------|-----|-----------|--------|------------|\n",
    "| Jessie | Windows 10 Education | 16GB | Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz 1.99 GHz | Yes | CPU times: total: 8.48s <br> Wall time: 1min 35s |\n",
    "| Adrianne | Windows 10 Pro | 16GB | Intel(R) Core(TM) i7-1165G7 @ 2.80GHz 2.80 GHz | Yes | CPU times: total: 6.23s <br> Wall time: 1min 7s |\n",
    "| Rada | Macbook Pro 2013 15\" | 16GB | 2.3 GHz Intel Core i7 | No | CPU times: total: 10.4 s<br>Wall time: 3min 5s |\n",
    "| Moid | Windows 11 Education | 12GB | 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz 1.38 GHz | Yes | CPU times: total: 6.81s <br> Wall time: 1min 31s |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6ba519-2c6d-4224-8531-2e7167833810",
   "metadata": {},
   "source": [
    "Macbook Pro took palpably longer than the rest for this process. Would be curious to review the reason."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96637ec-45ec-404a-831e-1c370d6a6439",
   "metadata": {},
   "source": [
    "# 4. Combining data CSVs\n",
    "\n",
    "- Combine data CSVs into a single CSV using pandas.\n",
    "\n",
    "- When combining the CSV files, add an extra column called \"model\" that identifies the model. Tip 1: you can get this column populated from the file name, eg: for file name \"SAM0-UNICON_daily_rainfall_NSW.csv\", the model name is SAM0-UNICON Tip 2: Remember how we added year when we combined airline CSVs. Tip 3: You can use regex generator.\n",
    "\n",
    "_Note: There is a file called observed_daily_rainfall_SYD.csv in the data folder that you downloaded. Make sure you exclude this file (programmatically or just take out that file from folder) before you combine CSVs. We will use this file in our next milestone._\n",
    "\n",
    "- Compare run times on different machines within your team and summarize your observations.\n",
    "Warning: Some of you might not be able to do it on your laptop. It's fine if you're unable to do it. Just make sure you discuss the reasons why you might not have been able to run this on your laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40676871-8964-4489-a541-0e84a7ac149c",
   "metadata": {},
   "source": [
    "Let's first view the data and the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf991be5-9a08-43ac-b12e-708d81bdc456",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_1 = pd.read_csv(output_directory+\"/MPI-ESM-1-2-HAM_daily_rainfall_NSW.csv\")\n",
    "df_2 = pd.read_csv(output_directory+\"/CMCC-CM2-SR5_daily_rainfall_NSW.csv\")\n",
    "df_3 = pd.read_csv(output_directory+\"/SAM0-UNICON_daily_rainfall_NSW.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e69142-a3fc-4b6f-81ad-b45a666263ef",
   "metadata": {},
   "source": [
    "Even loading three of the individual files is taking a little time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd74e93-83bc-45bd-9376-135b045e5702",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d56f6df-a1e0-494b-9c28-916ad97e95ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be8e1b4-58a5-4a0d-9044-9d358566f661",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49d1b94-dccd-4427-a814-081554396930",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9e0468-45da-419a-94dc-f0b576a9ed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "files = glob.glob('./rainfall/*NSW.csv')\n",
    "df = pd.concat((pd.read_csv(file, index_col=0)\n",
    "                .assign(model=re.findall(r'/([^_]*)', file)[0])\n",
    "                for file in files)\n",
    "              )\n",
    "df.to_csv(\"rainfall/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c64f81-752f-4c2d-80bc-a3b224980550",
   "metadata": {},
   "source": [
    "**For Windows user:**   \n",
    "Windows users will run into an index error when running the code above to combine the CSVs.   \n",
    "This can be solved by adding a ./ to the filename as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b7f1d9-b89d-4ae3-b3d4-6460016748a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%memit\n",
    "files = glob.glob('./rainfall/*NSW.csv')\n",
    "df = pd.concat((pd.read_csv(file, index_col=0)\n",
    "                .assign(model=file.strip('./rainfall\\\\').split('_')[0])\n",
    "                for file in files)\n",
    "              )\n",
    "df.to_csv(\"rainfall/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd16d5f7-77a6-4bcf-9cd7-98505b2a983c",
   "metadata": {},
   "source": [
    "Wow, this felt like an eternity!\n",
    "\n",
    "Let's take a look at the combined file, see if head and tail are as we expect them to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab6c92a-e605-4b11-b7d6-472e73a691cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2635431e-cbf1-4056-8638-4aa81ccc4987",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41611d5-c775-43c5-9422-4df1ddbd0333",
   "metadata": {},
   "source": [
    "## Comparison of Performance on Different Machines\n",
    "\n",
    "The summary of all team members' time taken to combine the CSV's files is recorded below. Each team member's Operating System, RAM, Processor and SSD are also recorded to check if they have any effect on the time taken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4cc9f7-345e-4c9c-90b5-ecd922fea905",
   "metadata": {},
   "source": [
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time Taken |\n",
    "|-------------|------------------|-----|-----------|--------|------------|\n",
    "| Jessie | Windows 10 Education | 16GB | Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz 1.99 GHz | Yes | peak memory: 800.19 MiB <br> increment: 0.00 MiB <br> CPU times: total: 8min 33s <br> Wall time: 8min 40s |\n",
    "| Adrianne | Windows 10 Pro | 16GB | Intel(R) Core(TM) i7-1165G7 @ 2.80GHz 2.80 GHz | Yes | peak memory: 120.25 MiB <br> increment: 0.30 MiB <br> CPU times: total: 7min 26s <br> Wall time: 7min 31s |\n",
    "| Rada | Macbook Pro 2013 15\" | 16GB | 2.3 GHz Intel Core i7 | No | peak memory: 3939.19 MiB <br> increment: 0.10 MiB <br> CPU times: user 7min 14s, sys: 21.5 s, total: 7min 36s  <br> Wall time: 7min 47s |\n",
    "| Moid | Windows 11 Education | 12GB | 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz 1.38 GHz | Yes | peak memory: 3622.16 MiB <br> increment: 0.72 MiB <br> CPU times: total: 7min 1s <br> Wall time: 7min 5s |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7940f07a-90db-4d37-b0e2-b81309929f48",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "Combining process is long in general at around 7-8 minutes, but quite consistent. Interesting to note the peak memory spikes on Macbook Pro and Windows i5 core machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b7fbb1-e064-4862-bfd7-366e4810b3e3",
   "metadata": {},
   "source": [
    "# 5. Load the combined CSV to memory and perform a simple EDA\n",
    "\n",
    "1. Investigate at least two of the following approaches to reduce memory usage while performing the EDA (e.g., value_counts).\n",
    "\n",
    "- Changing dtype of your data\n",
    "- Load just columns what we want\n",
    "- Loading in chunks\n",
    "- Dask\n",
    "\n",
    "2. Compare run times on different machines within your team and summarize your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01927b22-3abf-4ddd-b972-1391b3067bb1",
   "metadata": {},
   "source": [
    "**The EDA will be to use value_counts() to count the number of data points that came from each .csv file, as recorded in the model column of combined_data.csv.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16642faa-44e6-4a8b-bb6e-2aafe730d977",
   "metadata": {},
   "source": [
    "### 5.1 Load the Entire Dataframe to Memory Using Pandas (Baseline for Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b38fd63-c051-4f6a-9a54-ba7a66b7185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "df_pandas = pd.read_csv(\"rainfall/combined_data.csv\")\n",
    "print(df_pandas[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382ea113-f801-4c4c-ab36-f979c902ca79",
   "metadata": {},
   "source": [
    "**Observations**\n",
    ">Our baseline approach is to use Pandas to load the entire data to memory. The above code loads the combined_data.csv to memory and performs a simple EDA to calculate counts of values in the \"model\" column. We see that the peak memory is 9060 MiB and the CPU and wall time is 1min 31s. We will explore some other approaches to see if we can reduce the time and memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e74ea-8f2a-4748-ab28-9e704e8d89b6",
   "metadata": {},
   "source": [
    "### 5.2 Changing dtypes of data:\n",
    "\n",
    "- We will attempt to read the numerical columns using float32 format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c78aef6-e83a-44d2-9619-75d946e92a58",
   "metadata": {},
   "source": [
    "Memory comparison for format changes adapted from Lecture notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bb9533-b591-4e30-9f96-12c7ae5a4a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Memory usage with float64: {df[['lat_min','lat_max', 'lon_min', 'lon_max', 'rain (mm/day)']].memory_usage().sum() / 1e6:.2f} MB\")\n",
    "print(f\"Memory usage with float32: {df[['lat_min','lat_max', 'lon_min', 'lon_max', 'rain (mm/day)']].astype('float32', errors='ignore').memory_usage().sum() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8666e81b-c151-4de1-be4a-8f05e419da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_float32 = df.copy()\n",
    "df_float32[['lat_min','lat_max','lon_min', 'lon_max', 'rain (mm/day)']].astype('float32')\n",
    "\n",
    "#saving the dataframe of float32 to file\n",
    "df_float32.to_csv(\"rainfall/combined_data_float32.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e243f1be-cee8-48a8-a455-bc9c051f4a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "#loading the float32 dataframe to memory and perform a simple EDA for value counts of model column\n",
    "df_float32 = pd.read_csv(\"rainfall/combined_data_float32.csv\")\n",
    "print(df_float32[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae86de81-2d49-49c3-817c-41a28ec5a3f2",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "> When we changed the data type from float64 to float32 the memory usage reduced by nearly half. This is because float32 is stored as a 32-bit number, while float64 is stored as 64-bit number, which is twice as much memory as float32. With the EDA, we see that after converting dtypes to float 32, the peak memory usage decreased and the increment memory was halved. Both the CPU and wall time also decreased. Changing the dtype is effective in reducing the time and memory required to load data, and should be used when we have a large amount of data that does not require very high precision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f5c3d-f616-4cc2-a908-50aa9b72055e",
   "metadata": {},
   "source": [
    "### 5.3 Dask:\n",
    "\n",
    "- We will attempt to read dataframe using dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bdeaff-ec09-4819-a7c2-db4deeda9e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "# Dask\n",
    "df_dask = dd.read_csv('rainfall/combined_data.csv')\n",
    "print(df_dask[\"model\"].value_counts().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432e8485-ede7-4179-b7b2-3fee5b49fa00",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "> Using a Dask dataframe is much faster and lighter on memory. Compared to loading the csv to pandas data frame, when we load the csv file to dask, the peak memory, increment memory, and wall time all reduced significantly when calling the value_counts() function. This is likely because dask partitioned the dataframe based on row index and did the calculation in parallel to improve the efficiency. Thus, for large-scale data calculation, we could use dask instead of pandas to improve the code efficiency with minimal syntax change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bec6a11-a1c7-47b4-a86f-a44603bd07f2",
   "metadata": {},
   "source": [
    "### 5.4 Loading in Chunks:\n",
    "\n",
    "- We will attempt to read dataframe in chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c07eb0-bf10-4175-80c0-744af2d814f8",
   "metadata": {},
   "source": [
    "#### Chunksize = 10 million:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172e7a9f-6edb-424b-8e66-e6f0389336c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "counts = pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(\"rainfall/combined_data.csv\", chunksize=10_000_000):\n",
    "    counts = counts.add(chunk[\"model\"].value_counts(), fill_value=0)\n",
    "print(counts.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b3342-3ebc-4e5a-a0ad-63b229547c75",
   "metadata": {},
   "source": [
    "#### Chunksize = 1 million:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a37c04e-9ffb-4e8a-80e2-0212bf7b391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "counts = pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(\"rainfall/combined_data.csv\", chunksize=1_000_000):\n",
    "    counts = counts.add(chunk[\"model\"].value_counts(), fill_value=0)\n",
    "print(counts.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a142457-13db-45a4-9e49-26533081af6b",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "> When loading the data in chunks, the peak memory is significantly lower than that without using chunking method. We can see that loading in 10 million per chunk requires nearly 6800 MiB in peak memory usage, which is less than using Pandas to load all at once. Loading in 1 million per chunk requires only 3740 MiB in peak memory usage. The increment memory is almost 10 times less than using Pandas. This is significantly more efficient than using Pandas. However, we also notice that the CPU and wall time remains roughly the same in all these approaches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ca15d3-ce53-4422-9e26-7b505275ffe7",
   "metadata": {},
   "source": [
    "### 5.5 Selecting columns:\n",
    "\n",
    "Since we only want the model for EDA, we will import just the model column. This is faster and uses less memory than loading the whole dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c559aba-0717-48f7-bc1f-81ae8c4c0806",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df = pd.read_csv(\"rainfall/combined_data.csv\", \n",
    "                 usecols = [\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f323be2a-c344-4b9b-86c0-6b5ffd7b5f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df[\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c24e81-a7da-478f-bf35-987c6cf57509",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    ">Running value_counts takes the same time as it did using the entire data set, probably because it has to iterate through the same number of rows. However, this should still be done whenever possible because it reduces memory required and speeds up loading data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f9666a",
   "metadata": {},
   "source": [
    "**Here is a comparison of different machines on two approaches - changing data type and using Dask:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f1f477",
   "metadata": {},
   "source": [
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time Taken (changing dtype to float32) | Time Taken (Dask) |\n",
    "|-------------|------------------|-----|-----------|--------|----------------------------------------|-------------------|\n",
    "| Jessie | Windows 10 Education | 16GB | Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz 1.99 GHz | Yes | peak memory: 8487.61 MiB, increment: 2461.12 MiB <br> CPU times: total: 1min 44s <br> Wall time: 1min 46s | peak memory: 4749.06 MiB, increment: 1255.98 MiB <br> CPU times: total: 1min 8s <br> Wall time: 23.5s |\n",
    "| Adrianne | Windows 10 Pro | 16GB | Intel(R) Core(TM) i7-1165G7 @ 2.80GHz 2.80 GHz | Yes | peak memory: 13214.80 MiB, increment: 9233.91 MiB <br> CPU times: total: 55.4s <br> Wall time: 57s | peak memory: 4240.98 MiB, increment: 1255.65 MiB <br> CPU times: total: 57.2s <br> Wall time: 20.6s |\n",
    "| Rada | Macbook Pro 2013 15\" | 16GB | 2.3 GHz Intel Core i7 | No | peak memory: 4715.13 MiB, increment: 1308.29 MiB <br> CPU times: user 1min 9s, sys: 24.7 s, total: 1min 34s <br> Wall time: 1min 43s | peak memory: 3904.75 MiB, increment: 1306.16 MiB <br> CPU times: user 49.2 s, sys: 13.4 s, total: 1min 2s <br> Wall time: 23.2s |\n",
    "| Moid | Windows 11 Education | 12GB | 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz 1.38 GHz | Yes | peak memory: 9341.97 MiB, increment: 2808.60 MiB <br> CPU times: total: 1min 4s <br> Wall time: 1min 8s | peak memory: 3671.34 MiB, increment: 1263.45 MiB <br> CPU times: total: 1min 6s <br> Wall time: 23s |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63006133",
   "metadata": {},
   "source": [
    "### 5.6 Aggregation & Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9216da8-c2fd-4a38-b3d5-197fa1e7842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"rainfall/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecb2230-7a88-4fd6-afaa-dacce834759d",
   "metadata": {},
   "source": [
    "**Extracting Month and Year from Date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbf8f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda = df.copy()\n",
    "df_eda = df_eda.reset_index()\n",
    "df_eda.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0033a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df_eda['year'] = pd.DatetimeIndex(df_eda['time']).year\n",
    "df_eda['month'] = pd.DatetimeIndex(df_eda['time']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667c9ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d742d6-452e-4dc4-8e1b-f6749206b169",
   "metadata": {},
   "source": [
    "**Aggregation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4420be4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df_eda = df_eda[['model','year','rain (mm/day)']]\n",
    "df_eda = df_eda.groupby(['model', 'year']).agg('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e7c76d",
   "metadata": {},
   "source": [
    "**<center>Extracting Month and Year from Date, and Aggregation Times Comparison</center>**\n",
    "\n",
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time Taken (Extracting) | Time Taken (Aggregation) |\n",
    "|-------------|------------------|-----|-----------|--------|-------------------------|--------------------------|\n",
    "| Jessie      | Windows 10 Education |  16GB      |   Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz   1.99 GHz        |   Yes    | 1min 45s    | 13.1s\n",
    "| Adrianne    | Windows 10 Pro       |  16GB     | Intel(R) Core(TM) i7-1165G7 @ 2.80GHz 2.80 GHz                |   Yes     |  1min 27s |  12.3s\n",
    "| Rada        | Macbook Pro 2013 15\" |  16GB     | 2.3 GHz Intel Core i7                                         |   No      |  27.3 s  |   12.2s\n",
    "| Moid        |                      |           |                                                                |           |           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c692ed58-f211-411c-983d-768650b2446c",
   "metadata": {},
   "source": [
    "**Plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c72be37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda = df_eda.reset_index()\n",
    "df_eda.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b96ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "plot = alt.Chart(df_eda).mark_line().encode(\n",
    "    x='year',\n",
    "    y='rain (mm/day)',\n",
    "    color='model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d74f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "plot2 = alt.Chart(df_eda).mark_bar().encode(\n",
    "    x='rain (mm/day):Q',\n",
    "    y=alt.Y('model:N', sort='-x')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a72bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60edffd8",
   "metadata": {},
   "source": [
    "**<center>Plotting Times Comparison</center>**\n",
    "\n",
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time Taken (Plot1) | Time Taken (Plot2) |\n",
    "|-------------|------------------|-----|-----------|--------|--------------------|--------------------|\n",
    "| Jessie      | Windows 10 Education |  16GB      |   Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz   1.99 GHz        |   Yes    |  2.22s  | 2.45s\n",
    "| Adrianne    | Windows 10 Pro       |  16GB     | Intel(R) Core(TM) i7-1165G7 @ 2.80GHz 2.80 GHz                |   Yes     |  2.11s |  2.06s\n",
    "| Rada        | Macbook Pro 2013 15\" |  16GB     | 2.3 GHz Intel Core i7                                         |   No      |  1.43s  |   1.82s\n",
    "| Moid        |                      |           |                                                                |           |           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad2ac68-c355-45c4-a42f-456082879e82",
   "metadata": {},
   "source": [
    "# 6. Perform a simple EDA in R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d556d66-1dd5-4594-b1c8-3bcf015c9c52",
   "metadata": {},
   "source": [
    "To perform EDA in R, we first need to transfer the dataframe from Python to R.\n",
    "In this section, we will pass data from python to R in various ways and asses each method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4b97ee-224d-4711-81a6-6d224ca8ea26",
   "metadata": {},
   "source": [
    "## 6.1 Store the Data in Different Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d22021-6d55-41b9-93c6-6b3434250e4c",
   "metadata": {},
   "source": [
    "### 6.1.1 Arrow file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1791571a-601c-4c65-80da-f4f53109350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#Loading library\n",
    "library(arrow);\n",
    "library(dplyr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae424c3-dabe-45cf-9c61-fe4fe8090c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "dataset = ds.dataset(\"rainfall/combined_data.csv\", format=\"csv\")\n",
    "\n",
    "table = dataset.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d002a84-b8c0-470f-8cbc-4346c09aaffe",
   "metadata": {},
   "source": [
    "### 6.1.2 Feather format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef5510f-b285-4951-9769-8a97e70a732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "feather.write_feather(table, 'rainfall/combined_data.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdd7906-6bce-4341-86e9-cc4c5d8829e1",
   "metadata": {},
   "source": [
    "Evidently, feather format comes with over 3x Wall time improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796ee1cc-5937-4896-8814-c698bcf9a5f2",
   "metadata": {},
   "source": [
    "### 6.1.3 Parquet format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa622966-5564-423e-be5e-707217d6ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## writing as a single parquet \n",
    "pq.write_table(table, 'rainfall/combined_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc188151-37fd-41b1-be87-af95099f6da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## writing as a partitioned parquet \n",
    "pq.write_to_dataset(table, 'rainfall/combined_data_partitioned.parquet',partition_cols=['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff29c01a-417e-4d25-b196-bfdda24e996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# Check the size of different format\n",
    "du -sh rainfall/combined_data.csv\n",
    "du -sh rainfall/combined_data.feather\n",
    "du -sh rainfall/combined_data.parquet\n",
    "du -sh rainfall/combined_data_partitioned.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd0a49f-fbcb-4646-bb6d-b9e53e234537",
   "metadata": {},
   "source": [
    ">We can see that both Feather and Parquet have reduced the file size significantly. The wall time taken for feather and single parquet was much less than Arrow. Partitioned parquet took similar wall time as Arrow but it significantly reduced the file size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d620597d-5093-4c5d-9895-9bab9266d5fb",
   "metadata": {},
   "source": [
    "## 6.2 Transfer the Data in Different Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2e2f6f-dbba-43b1-bcb3-7ae12143d504",
   "metadata": {},
   "source": [
    "### 6.2.1 Pandas Exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebae683-f571-4708-9401-61e628c46c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "#simple pandas: read the entire dataset into memory\n",
    "df = pd.read_csv(\"rainfall/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba032d9e-3269-4101-a14c-ce078a8669d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R -i df\n",
    "start_time <- Sys.time()\n",
    "library(dplyr)\n",
    "# print(class(df))\n",
    "result <- df |> count(model)\n",
    "#print(result)\n",
    "end_time <- Sys.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fa6945-4694-4e20-9a7d-1af44571a4e3",
   "metadata": {},
   "source": [
    "### 6.2.2 Arrow Exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2571cb4-591b-4193-8045-cc417f952035",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "dataset = ds.dataset(\"rainfall/combined_data.csv\", format=\"csv\")\n",
    "table = dataset.to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e1e2c5-1b37-4672-bce9-2dcd5235e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "## Here we are converting arrow table so it can be passed to R\n",
    "r_table = pyra.converter.py2rpy(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31674021-c79c-4592-acb7-1af67a2e1361",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R -i r_table\n",
    "# Pass r_table from python\n",
    "\n",
    "start_time <- Sys.time()\n",
    "library(dplyr)\n",
    "counts <- r_table %>% collect() %>% count(model)\n",
    "end_time <- Sys.time()\n",
    "\n",
    "print(counts)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca4a476-55b9-4baa-9606-03f42fccac6a",
   "metadata": {},
   "source": [
    "### 6.2.3 Feather File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d04fcff-5bb6-491e-8534-523d7007818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "library(arrow)\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_feather(\"rainfall/combined_data.feather\")\n",
    "print(class(r_table))\n",
    "library(dplyr)\n",
    "result <- r_table %>% count(model) \n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb8ff2b-fab0-4cdb-890c-dc3112349d0c",
   "metadata": {},
   "source": [
    "### 6.2.4 Parquet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151b0d7-28d6-4303-9fad-c92ee8b46050",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "library(arrow)\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_parquet(\"rainfall/combined_data.parquet\")\n",
    "print(class(r_table))\n",
    "library(dplyr)\n",
    "result <- r_table %>% count(model)\n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3684fea6",
   "metadata": {},
   "source": [
    "### 6.3 Aggregation & Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c91567",
   "metadata": {},
   "source": [
    "Rename the column because it's easier to work that way in R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b5b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "r_table <- r_table %>% \n",
    "  rename(\n",
    "    rain = `rain (mm/day)`,\n",
    "    )\n",
    "start_time <- Sys.time()\n",
    "glimpse(r_table)\n",
    "end_time <- Sys.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e10a3b4",
   "metadata": {},
   "source": [
    "**Aggregate by Model only:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f88185",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "start_time <- Sys.time()\n",
    "summ_rain <- r_table %>% \n",
    "  group_by(model) %>%\n",
    "  summarise(mean_rain = mean(rain, na.rm = TRUE))\n",
    "end_time <- Sys.time()\n",
    "print(end_time - start_time)\n",
    "summ_rain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c800b0f",
   "metadata": {},
   "source": [
    "**Extract Month and Year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d602280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "library(lubridate)\n",
    "start_time <- Sys.time()\n",
    "year_month_table <- r_table %>% \n",
    "  mutate(year = year(time), month = month(time))\n",
    "end_time <- Sys.time()\n",
    "print(end_time - start_time)\n",
    "year_month_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8a1943",
   "metadata": {},
   "source": [
    "**Aggregated by Model and by Year:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "start_time <- Sys.time()\n",
    "summ_rain_2 <- year_month_table %>% \n",
    "  group_by(model, year, month) %>%\n",
    "  summarise(mean_rain = mean(rain, na.rm = TRUE))\n",
    "end_time <- Sys.time()\n",
    "print(end_time - start_time)\n",
    "summ_rain_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e633778c",
   "metadata": {},
   "source": [
    "**<center>Extracting Month and Year from Date, and Aggregation Times Comparison</center>**\n",
    "\n",
    "| Team Member | Operating System | RAM | Processor | Is SSD | Time Taken (Extracting) | Time Taken (Aggregation) |\n",
    "|-------------|------------------|-----|-----------|--------|-------------------------|--------------------------|\n",
    "| Jessie      | Windows 10 Education |  16GB      |   Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz   1.99 GHz        |   Yes    |  25.3s  |  6.02s\n",
    "| Adrianne    | Windows 10 Pro       |  16GB     | Intel(R) Core(TM) i7-1165G7 @ 2.80GHz 2.80 GHz                |   Yes     |  18.6 s  |   5.05s\n",
    "| Rada        | Macbook Pro 2013 15\" |  16GB     | 2.3 GHz Intel Core i7                                         |   No      |  53.2 s  |   5.57s\n",
    "| Moid        |                      |           |                                                                |           |           |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77463db9-41c6-43b8-aa20-df965528ba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "library(ggplot2)\n",
    "start_time <- Sys.time()\n",
    "plot <- summ_rain_2 %>% ggplot(aes(x = year, y = mean_rain, color = model)) + geom_line()\n",
    "end_time <- Sys.time()\n",
    "print(end_time - start_time)\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff70f98e-0321-4a9d-9373-d919940b41f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "library(ggplot2)\n",
    "start_time <- Sys.time()\n",
    "plot2 <- summ_rain %>% ggplot(aes(x = mean_rain, y = model)) + geom_bar(stat = \"identity\")\n",
    "end_time <- Sys.time()\n",
    "print(end_time - start_time)\n",
    "plot2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4e6218-829a-4a13-82c7-ed43228a05ea",
   "metadata": {},
   "source": [
    "**<center>Plotting Times Comparison</center>**\n",
    "\n",
    "| Team Member | Operating System     | RAM       | Processor                                                     | Is SSD   | Time Taken (Plot1) | Time Taken (Plot2) |\n",
    "| ----------- | -----------          |-----------| ---------- ---------------------------------------------------|----------|---------  --------------|  --------------      |\n",
    "| Jessie      | Windows 10 Education |  16GB      |   Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz   1.99 GHz        |   Yes    |   1.55s                      | 1.14s\n",
    "| Adrianne    | Windows 10 Pro       |  16GB     | Intel(R) Core(TM) i7-1165G7 @ 2.80GHz 2.80 GHz                |   Yes     |  1.28s                 |   0.139s |\n",
    "| Rada        | Macbook Pro 2013 15\" |  16GB     | 2.3 GHz Intel Core i7                                         |   No      |  1.22s                 |   1.43s\n",
    "| Moid        |                      |           |                                                                |           |                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a698807-c796-4212-8a99-23f6252f9eda",
   "metadata": {},
   "source": [
    "## Observations Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295d73d4-1ab3-4cb1-9663-5c6683eb98af",
   "metadata": {},
   "source": [
    "### File manipulation:  \n",
    "\n",
    "Downloading and unzipping the rainfall file took 6-11sec, with Windows machines fairing better than the Macbook.\n",
    "\n",
    "Combining the data by simple concatenation took about 7-8min. Windows 10 Edu machine took the longest, but Macbook pro and Windows i5 core had a scary high peak memory at about 1/4 of its total RAM. Another interesting thing to note is the memory increment on an Windows i5 core machine is double of that on an i7 core.\n",
    "\n",
    "### Loading Data into R:\n",
    "\n",
    "We attempted several methods of loading the data into R, after previous work in pandas.   \n",
    "Loading only the columns we needed reduced loading times from raw of a bit over 1min to ~5sec. Loading using more suited memory-smart data types of float32 instead of float64 cut loading time roughly in half.\n",
    "\n",
    "For value counts EDA, raw **Pandas** took a very long time, upwards of 40 minutes for each of us.   \n",
    "This baseline looked intimidating. Fortunately, every alternative method improved the processing time significantly.   \n",
    "\n",
    "**Arrow** exchange ~26, **Feather** loading ~8sec, **Parquet** ~11sec and **partitioned Parquet** which comes with some more optimization ~35sec.   \n",
    "And this is for a very large file with upwards of 62 million observations. Parquet is clearly a very good tool for loading the data.\n",
    "\n",
    "With that in mind, for files of this magnitude in the future, we would lean loading the data using **Parquet**, because it's optimized for working with large files and is comparable with alternative techniques.\n",
    "\n",
    "### EDA Comparisons\n",
    "\n",
    "Different file loading techniques resulted in various time savings for the purposes of simple EDA computing value counts.   \n",
    "When loaded with **Arrow**, counting took ~53sec, with **Feather** ~20sec, with **Paraquet** ~10sec. Again, **Parquet** is proving to be a good tool for this kind of processing.\n",
    "\n",
    "For the extraction of year/month from date, times varied a lot based on the run, but overall Pandas took ~12sec and R took ~40sec.\n",
    "For the simple aggergation process, Pandas took ~6-10sec, and R took ~3-5sec to perform the same operation.\n",
    "Plotting process was simple and fast despite once the data was aggregated, under 2sec per plot for both Pandas and R. Of course, plotting usually requires aggregation in the first place: it's rare that the user will be able to make sense of millions of data points of non-aggregated data. So really, the aggregation times are more important to quantify here, because it is unlikely that plotting of millions of points will ever come up in practice.\n",
    "\n",
    "\n",
    "### Machine Comparison Overall: \n",
    "\n",
    "In general, we didn't have a particularly wide variety of machine: each of us are on a 16GB RAM and Intel core.   \n",
    "We did have both Macbook and Windows machines to test the results.   \n",
    "It appears that the times are fairly consistent between operating systems.\n",
    "In fact, while we only recorded final times and memory usages for each step per laptop, rerunning the notebook several times resulted in similar variation in times and memory usage to what we got from using different laptops.   \n",
    "However, for most of the processes, Macbook machine was performing worse than others. A lot more tests on similar computers would need to be performed to get meaningful performance comparison because the Macbook is very old (2013) so besides the components of the build, wear and tear could affect the process timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ced55c6-0a54-4628-a6d0-ba61c0e46cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f25c1b085bda671884cb3d2c565b233d1145a4f72639fa756796e207cd4b76ec"
  },
  "kernelspec": {
   "display_name": "Python [conda env:525_2022]",
   "language": "python",
   "name": "conda-env-525_2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
