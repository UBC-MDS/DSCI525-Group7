{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b854f4ee-3a3c-4273-8c32-9cbe4aa4546a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64811e1-9064-4578-9ab0-bef2d10afd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# pyarrow and feather\n",
    "import pyarrow.feather as feather\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import rpy2_arrow.pyarrow_rarrow as pyra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "933642a1-e811-4fdc-a613-26f675f22ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5976a30-5808-477f-abb2-cc4a464ca8a4",
   "metadata": {},
   "source": [
    "# 1. Teamwork Contract\n",
    "The teamwork contract for our team, group 7, can be found [here](https://docs.google.com/document/d/1u4e5Z5C-uwTTSvCEyOYy-I30Fb8OEPYM6frM0NBEVVc/edit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9aee01-4eb9-4a7b-8920-802d235f9199",
   "metadata": {},
   "source": [
    "# 2. Create repository and project structure\n",
    "The repository URL: https://github.com/UBC-MDS/DSCI525-Group7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e53d5d4-a952-4b38-84cf-7b96510045c4",
   "metadata": {},
   "source": [
    "# 3. Downloading the data\n",
    "\n",
    "Using Python **requests** Library\n",
    "\n",
    "We are using article id #14096681, which contains the data of **Daily rainfall over NSW, Australia.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c326b50-df61-4679-b95c-7c5e18cc9a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "article_id = 14096681  \n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"rainfall/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de6fe8-cef7-4184-94c6-82f29e2cfd42",
   "metadata": {},
   "source": [
    "Review the files within the article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e03159ea-764b-46fc-8a20-249e5529894b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 26579150,\n",
       "  'name': 'daily_rainfall_2014.png',\n",
       "  'size': 58863,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579150',\n",
       "  'supplied_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'computed_md5': 'fd32a2ffde300a31f8d63b1825d47e5e'},\n",
       " {'id': 26579171,\n",
       "  'name': 'environment.yml',\n",
       "  'size': 192,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579171',\n",
       "  'supplied_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'computed_md5': '060b2020017eed93a1ee7dd8c65b2f34'},\n",
       " {'id': 26586554,\n",
       "  'name': 'README.md',\n",
       "  'size': 5422,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26586554',\n",
       "  'supplied_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'computed_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c'},\n",
       " {'id': 26766812,\n",
       "  'name': 'data.zip',\n",
       "  'size': 814041183,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766812',\n",
       "  'supplied_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'computed_md5': 'b517383f76e77bd03755a63a8ff83ee9'},\n",
       " {'id': 26766815,\n",
       "  'name': 'get_data.py',\n",
       "  'size': 4113,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766815',\n",
       "  'supplied_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'computed_md5': '7829028495fd9dec9680ea013474afa6'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # this contains all the articles data, feel free to check it out\n",
    "files = data[\"files\"]             # this is just the data about the files, which is what we want\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e52d215-05c2-48a4-834b-4e1f71890473",
   "metadata": {},
   "source": [
    "# 3.1 Unzipping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c5cf54-861a-4e80-8a72-cdfdaca747ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.64 s, sys: 3.42 s, total: 7.07 s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "files_to_dl = [\"data.zip\"]  \n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a659d0f5-fbce-4e61-8c93-dba0e36e82a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(os.path.join(output_directory, \"data.zip\"), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62750636-4ddb-4e19-a4d2-bab89e561242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12294480\n",
      "-rw-r--r--   1 Rada  staff  814041183 30 Mar 10:08 data.zip\n",
      "-rw-r--r--   1 Rada  staff   95376895 30 Mar 10:08 MPI-ESM-1-2-HAM_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff   94960113 30 Mar 10:08 AWI-ESM-1-1-LR_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff   82474546 30 Mar 10:08 NorESM2-LM_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff  127613760 30 Mar 10:08 ACCESS-CM2_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff  232118894 30 Mar 10:09 FGOALS-f3-L_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff  330360682 30 Mar 10:09 CMCC-CM2-HR4_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff  254009247 30 Mar 10:09 MRI-ESM2-0_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff  235661418 30 Mar 10:09 GFDL-CM4_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff  294260911 30 Mar 10:09 BCC-CSM2-MR_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff  295768615 30 Mar 10:09 EC-Earth3-Veg-LR_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff  328852379 30 Mar 10:09 CMCC-ESM2_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff   67784105 30 Mar 10:09 NESM3_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff   95640682 30 Mar 10:09 MPI-ESM1-2-LR_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff  114707410 30 Mar 10:09 ACCESS-ESM1-5_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff  116179272 30 Mar 10:09 FGOALS-g3_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff  102517965 30 Mar 10:09 INM-CM4-8_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff  515458033 30 Mar 10:09 MPI-ESM1-2-HR_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff  332813281 30 Mar 10:09 TaiESM1_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff  337555851 30 Mar 10:09 NorESM2-MM_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff  328787320 30 Mar 10:09 CMCC-CM2-SR5_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff     952202 30 Mar 10:09 observed_daily_rainfall_SYD.csv\n",
      "-rw-r--r--   1 Rada  staff   93829697 30 Mar 10:09 KIOST-ESM_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff  102692289 30 Mar 10:09 INM-CM5-0_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff  206822938 30 Mar 10:09 MIROC6_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff   55224437 30 Mar 10:09 BCC-ESM1_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff  124586961 30 Mar 10:09 GFDL-ESM4_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff   46286371 30 Mar 10:09 CanESM5_daily_rainfall_NSW.csv\n",
      "-rw-r--r--   1 Rada  staff  333489879 30 Mar 10:09 SAM0-UNICON_daily_rainfall_NSW.csv\n",
      "drwxr-xr-x  30 Rada  staff        960 30 Mar 10:09 \u001b[1m\u001b[34m__MACOSX\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "%ls -ltr rainfall/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b56f5-8d99-4085-aa8f-bcc95b6a6c40",
   "metadata": {},
   "source": [
    "# Comparison of Performance on Different Machines\n",
    "\n",
    "The summary of all team members' time taken to unzip the data is recorded below. Each team member's Operating System, RAM, Processor and SSD are also recorded to check if they have any effect on the time taken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd7aa16-f118-4b18-b1a7-bdcadb5f505a",
   "metadata": {},
   "source": [
    "| Team Member | Operating System     | RAM       | Processor                                                      | Is SSD   | Time Taken |\n",
    "| ----------- | -----------          |-----------| ---------- ---------------------------------------------------|----------|---------  -|\n",
    "| Jessie      | Windows 10 Education |  16GB      |   Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz   1.99 GHz        |   Yes    |  CPU times: total: 8.48 s <br> Wall time: 1min 35s          |\n",
    "| Adrianne    | Windows 10 Pro       |  16GB     | Intel(R) Core(TM) i7-1165G7 @ 2.80GHz 2.80 GHz                |   Yes     | CPU times: total: 6.23 s <br> Wall time: 1min 7s          |\n",
    "| Rada        |                      |           |                                                               |           |           |\n",
    "| Moid        |                      |           |                                                                |           |           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6ba519-2c6d-4224-8531-2e7167833810",
   "metadata": {},
   "source": [
    ">**Discussion of results above**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96637ec-45ec-404a-831e-1c370d6a6439",
   "metadata": {},
   "source": [
    "# 4. Combining data CSVs\n",
    "\n",
    "- Combine data CSVs into a single CSV using pandas.\n",
    "\n",
    "- When combining the CSV files, add an extra column called \"model\" that identifies the model. Tip 1: you can get this column populated from the file name, eg: for file name \"SAM0-UNICON_daily_rainfall_NSW.csv\", the model name is SAM0-UNICON Tip 2: Remember how we added year when we combined airline CSVs. Tip 3: You can use regex generator.\n",
    "\n",
    "_Note: There is a file called observed_daily_rainfall_SYD.csv in the data folder that you downloaded. Make sure you exclude this file (programmatically or just take out that file from folder) before you combine CSVs. We will use this file in our next milestone._\n",
    "\n",
    "- Compare run times on different machines within your team and summarize your observations.\n",
    "Warning: Some of you might not be able to do it on your laptop. It's fine if you're unable to do it. Just make sure you discuss the reasons why you might not have been able to run this on your laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40676871-8964-4489-a541-0e84a7ac149c",
   "metadata": {},
   "source": [
    "Let's first view the data and the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf991be5-9a08-43ac-b12e-708d81bdc456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.21 s, sys: 1 s, total: 8.21 s\n",
      "Wall time: 8.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_1 = pd.read_csv(output_directory+\"/MPI-ESM-1-2-HAM_daily_rainfall_NSW.csv\")\n",
    "df_2 = pd.read_csv(output_directory+\"/CMCC-CM2-SR5_daily_rainfall_NSW.csv\")\n",
    "df_3 = pd.read_csv(output_directory+\"/SAM0-UNICON_daily_rainfall_NSW.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e69142-a3fc-4b6f-81ad-b45a666263ef",
   "metadata": {},
   "source": [
    "Even loading three of the individual files is taking a little time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cd74e93-83bc-45bd-9376-135b045e5702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.244226e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.217326e-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time    lat_min    lat_max   lon_min   lon_max  \\\n",
       "0  1889-01-01 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "1  1889-01-02 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "\n",
       "   rain (mm/day)  \n",
       "0   4.244226e-13  \n",
       "1   4.217326e-13  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d56f6df-a1e0-494b-9c28-916ad97e95ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>0.000424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>0.006158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time    lat_min   lat_max  lon_min  lon_max  rain (mm/day)\n",
       "0  1889-01-01 12:00:00 -35.811518 -34.86911  140.625  141.875       0.000424\n",
       "1  1889-01-02 12:00:00 -35.811518 -34.86911  140.625  141.875       0.006158"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7be8e1b4-58a5-4a0d-9044-9d358566f661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>3.045650e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>3.572392e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time    lat_min   lat_max  lon_min  lon_max  rain (mm/day)\n",
       "0  1889-01-01 12:00:00 -35.811518 -34.86911  140.625  141.875   3.045650e-13\n",
       "1  1889-01-02 12:00:00 -35.811518 -34.86911  140.625  141.875   3.572392e-04"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f49d1b94-dccd-4427-a814-081554396930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3541151</th>\n",
       "      <td>2014-12-30 12:00:00</td>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>8.541592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541152</th>\n",
       "      <td>2014-12-31 12:00:00</td>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>68.117489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time    lat_min   lat_max  lon_min  lon_max  \\\n",
       "3541151  2014-12-30 12:00:00 -30.157068 -29.21466  153.125  154.375   \n",
       "3541152  2014-12-31 12:00:00 -30.157068 -29.21466  153.125  154.375   \n",
       "\n",
       "         rain (mm/day)  \n",
       "3541151       8.541592  \n",
       "3541152      68.117489  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f9e0468-45da-419a-94dc-f0b576a9ed11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 21s, sys: 21 s, total: 7min 42s\n",
      "Wall time: 7min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "files = glob.glob('rainfall/*NSW.csv')\n",
    "df = pd.concat((pd.read_csv(file, index_col=0)\n",
    "                .assign(model=re.findall(r'/([^_]*)', file)[0])\n",
    "                for file in files)\n",
    "              )\n",
    "df.to_csv(\"rainfall/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50c64f81-752f-4c2d-80bc-a3b224980550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Windows user \n",
    "##  Windows users will run into an index error when running the code above to combine the CSVs. This can be solved by adding a ./ to the filename as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18b7f1d9-b89d-4ae3-b3d4-6460016748a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3939.19 MiB, increment: 0.10 MiB\n",
      "CPU times: user 7min 14s, sys: 21.5 s, total: 7min 36s\n",
      "Wall time: 7min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "files = glob.glob('./rainfall/*NSW.csv')\n",
    "df = pd.concat((pd.read_csv(file, index_col=0)\n",
    "                .assign(model=file.strip('./rainfall\\\\').split('_')[0])\n",
    "                for file in files)\n",
    "              )\n",
    "df.to_csv(\"rainfall/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd16d5f7-77a6-4bcf-9cd7-98505b2a983c",
   "metadata": {},
   "source": [
    "Wow, this felt like an eternity!\n",
    "\n",
    "Let's take a look at the combined file, see if head and tail are as we expect them to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bab6c92a-e605-4b11-b7d6-472e73a691cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1889-01-01 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.244226e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-02 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.217326e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-03 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.498125e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-04 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.251282e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-05 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.270161e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       lat_min    lat_max   lon_min   lon_max  rain (mm/day)  \\\n",
       "time                                                                           \n",
       "1889-01-01 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.244226e-13   \n",
       "1889-01-02 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.217326e-13   \n",
       "1889-01-03 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.498125e-13   \n",
       "1889-01-04 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.251282e-13   \n",
       "1889-01-05 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.270161e-13   \n",
       "\n",
       "                               model  \n",
       "time                                  \n",
       "1889-01-01 12:00:00  MPI-ESM-1-2-HAM  \n",
       "1889-01-02 12:00:00  MPI-ESM-1-2-HAM  \n",
       "1889-01-03 12:00:00  MPI-ESM-1-2-HAM  \n",
       "1889-01-04 12:00:00  MPI-ESM-1-2-HAM  \n",
       "1889-01-05 12:00:00  MPI-ESM-1-2-HAM  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2635431e-cbf1-4056-8638-4aa81ccc4987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-27 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>6.689683</td>\n",
       "      <td>SAM0-UNICON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-28 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>7.862555</td>\n",
       "      <td>SAM0-UNICON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-29 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>10.005026</td>\n",
       "      <td>SAM0-UNICON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>8.541592</td>\n",
       "      <td>SAM0-UNICON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>68.117489</td>\n",
       "      <td>SAM0-UNICON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       lat_min   lat_max  lon_min  lon_max  rain (mm/day)  \\\n",
       "time                                                                        \n",
       "2014-12-27 12:00:00 -30.157068 -29.21466  153.125  154.375       6.689683   \n",
       "2014-12-28 12:00:00 -30.157068 -29.21466  153.125  154.375       7.862555   \n",
       "2014-12-29 12:00:00 -30.157068 -29.21466  153.125  154.375      10.005026   \n",
       "2014-12-30 12:00:00 -30.157068 -29.21466  153.125  154.375       8.541592   \n",
       "2014-12-31 12:00:00 -30.157068 -29.21466  153.125  154.375      68.117489   \n",
       "\n",
       "                           model  \n",
       "time                              \n",
       "2014-12-27 12:00:00  SAM0-UNICON  \n",
       "2014-12-28 12:00:00  SAM0-UNICON  \n",
       "2014-12-29 12:00:00  SAM0-UNICON  \n",
       "2014-12-30 12:00:00  SAM0-UNICON  \n",
       "2014-12-31 12:00:00  SAM0-UNICON  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41611d5-c775-43c5-9422-4df1ddbd0333",
   "metadata": {},
   "source": [
    "## Comparison of Performance on Different Machines\n",
    "\n",
    "The summary of all team members' time taken to combine the CSV's files is recorded below. Each team member's Operating System, RAM, Processor and SSD are also recorded to check if they have any effect on the time taken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4cc9f7-345e-4c9c-90b5-ecd922fea905",
   "metadata": {},
   "source": [
    "| Team Member | Operating System     | RAM       | Processor                                                      | Is SSD   | Time Taken |\n",
    "| ----------- | -----------          |-----------| ---------- ---------------------------------------------------|----------|---------  -|\n",
    "| Jessie      | Windows 10 Education |  16GB      |   Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz   1.99 GHz        |   Yes    |  peak memory: 800.19 MiB  increment: 0.00 MiB <br> CPU times: total: 8min 33s <br> Wall time: 8min 40s          |\n",
    "| Adrianne    | Windows 10 Pro       |  16GB     | Intel(R) Core(TM) i7-1165G7 @ 2.80GHz 2.80 GHz                |   Yes     | peak memory: 120.25 MiB, increment: 0.30 MiB <br> CPU times: total: 7min 26s <br> Wall time: 7min 31s          |\n",
    "| Rada        | Macbook Pro 2013 15\" |  16GB     | 2.3 GHz Intel Core i7                                         |   No      | peak memory: 3939.19 MiB, increment: 0.10 MiB <br> CPU times: user 7min 14s, sys: 21.5 s, total: 7min 36s  <br> Wall time: 7min 47s           |\n",
    "| Moid        |                      |           |                                                                |           |           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7940f07a-90db-4d37-b0e2-b81309929f48",
   "metadata": {},
   "source": [
    "> **Discussion of results above** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b7fbb1-e064-4862-bfd7-366e4810b3e3",
   "metadata": {},
   "source": [
    "# 5. Load the combined CSV to memory and perform a simple EDA\n",
    "\n",
    "1. Investigate at least two of the following approaches to reduce memory usage while performing the EDA (e.g., value_counts).\n",
    "\n",
    "- Changing dtype of your data\n",
    "- Load just columns what we want\n",
    "- Loading in chunks\n",
    "- Dask\n",
    "\n",
    "2. Compare run times on different machines within your team and summarize your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01927b22-3abf-4ddd-b972-1391b3067bb1",
   "metadata": {},
   "source": [
    "**The EDA will be to use value_counts() to count the number of data points that came from each .csv file, as recorded in the model column of combined_data.csv.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16642faa-44e6-4a8b-bb6e-2aafe730d977",
   "metadata": {},
   "source": [
    "### 5.1 Load the Entire Dataframe to Memory Using Pandas (Baseline for Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b38fd63-c051-4f6a-9a54-ba7a66b7185a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-ESM2           3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "NorESM2-MM          3541230\n",
      "TaiESM1             3541230\n",
      "SAM0-UNICON         3541153\n",
      "GFDL-ESM4           3219300\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "MRI-ESM2-0          3037320\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "FGOALS-g3           1287720\n",
      "KIOST-ESM           1287720\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "Name: model, dtype: int64\n",
      "peak memory: 7451.22 MiB, increment: 3863.56 MiB\n",
      "CPU times: user 1min 6s, sys: 18.9 s, total: 1min 25s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "df_pandas = pd.read_csv(\"rainfall/combined_data.csv\")\n",
    "print(df_pandas[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382ea113-f801-4c4c-ab36-f979c902ca79",
   "metadata": {},
   "source": [
    "**Observations**\n",
    ">Our baseline approach is to use Pandas to load the entire data to memory. The above code loads the combined_data.csv to memory and performs a simple EDA to calculate counts of values in the \"model\" column. We see that the peak memory is 9060 MiB and the CPU and wall time is 1min 31s. We will explore some other approaches to see if we can reduce the time and memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e74ea-8f2a-4748-ab28-9e704e8d89b6",
   "metadata": {},
   "source": [
    "### 5.2 Python EDA\n",
    "\n",
    "We will perform an EDA on value counts and compare the execution time and memory required on 4 approaches:\n",
    "- Change data type to float32\n",
    "- Dask\n",
    "- Load data in chunks of 10 millions and 1 million\n",
    "- Select only columns of interest\n",
    "\n",
    "\n",
    "### 5.2.1 Changing dtypes of data:\n",
    "\n",
    "- We will attempt to change time column from datetime to date\n",
    "- We will attempt to read the numerical columns using float32 format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c78aef6-e83a-44d2-9619-75d946e92a58",
   "metadata": {},
   "source": [
    "Memory comparison for format changes adapted from Lecture notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "800f52fc-640e-4e20-9826-721f5fefc3d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DatetimeIndex' object has no attribute 'dt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241m.\u001b[39mdate\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DatetimeIndex' object has no attribute 'dt'"
     ]
    }
   ],
   "source": [
    "df.index = pd.to_datetime(df.index).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9bb9533-b591-4e30-9f96-12c7ae5a4a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage with float64: 2998.46 MB\n",
      "Memory usage with float32: 1749.10 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory usage with float64: {df[['lat_min','lat_max', 'lon_min', 'lon_max', 'rain (mm/day)']].memory_usage().sum() / 1e6:.2f} MB\")\n",
    "print(f\"Memory usage with float32: {df[['lat_min','lat_max', 'lon_min', 'lon_max', 'rain (mm/day)']].astype('float32', errors='ignore').memory_usage().sum() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8666e81b-c151-4de1-be4a-8f05e419da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_float32 = df.copy()\n",
    "df_float32[['lat_min','lat_max','lon_min', 'lon_max', 'rain (mm/day)']].astype('float32')\n",
    "\n",
    "#saving the dataframe of float32 to file\n",
    "df_float32.to_csv(\"rainfall/combined_data_float32.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e243f1be-cee8-48a8-a455-bc9c051f4a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-ESM2           3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "NorESM2-MM          3541230\n",
      "TaiESM1             3541230\n",
      "SAM0-UNICON         3541153\n",
      "GFDL-ESM4           3219300\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "MRI-ESM2-0          3037320\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "FGOALS-g3           1287720\n",
      "KIOST-ESM           1287720\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "Name: model, dtype: int64\n",
      "peak memory: 4715.13 MiB, increment: 1308.29 MiB\n",
      "CPU times: user 1min 9s, sys: 24.7 s, total: 1min 34s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "#loading the float32 dataframe to memory and perform a simple EDA for value counts of model column\n",
    "df_float32 = pd.read_csv(\"rainfall/combined_data_float32.csv\")\n",
    "print(df_float32[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae86de81-2d49-49c3-817c-41a28ec5a3f2",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "> When we changed the data type from float64 to float32 the memory usage reduced by nearly half. This is because float32 is stored as a 32-bit number, while float64 is stored as 64-bit number, which is twice as much memory as float32. With the EDA, we see that after converting dtypes to float 32, the peak memory usage decreased and the increment memory was halved. Both the CPU and wall time also decreased. Changing the dtype is effective in reducing the time and memory required to load data, and should be used when we have a large amount of data that does not require very high precision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f5c3d-f616-4cc2-a908-50aa9b72055e",
   "metadata": {},
   "source": [
    "### 5.2.2 Dask:\n",
    "\n",
    "- We will attempt to read dataframe using dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8bdeaff-ec09-4819-a7c2-db4deeda9e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "TaiESM1             3541230\n",
      "NorESM2-MM          3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "SAM0-UNICON         3541153\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "MRI-ESM2-0          3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM5-0           1609650\n",
      "INM-CM4-8           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "Name: model, dtype: int64\n",
      "peak memory: 3904.75 MiB, increment: 1306.16 MiB\n",
      "CPU times: user 49.2 s, sys: 13.4 s, total: 1min 2s\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "# Dask\n",
    "df_dask = dd.read_csv('rainfall/combined_data.csv')\n",
    "print(df_dask[\"model\"].value_counts().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432e8485-ede7-4179-b7b2-3fee5b49fa00",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "> Using a Dask dataframe is much faster and lighter on memory. Compared to loading the csv to pandas data frame, when we load the csv file to dask, the peak memory, increment memory, and wall time all reduced significantly when calling the value_counts() function. This is likely because dask partitioned the dataframe based on row index and did the calculation in parallel to improve the efficiency. Thus, for large-scale data calculation, we could use dask instead of pandas to improve the code efficiency with minimal syntax change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bec6a11-a1c7-47b4-a86f-a44603bd07f2",
   "metadata": {},
   "source": [
    "### 5.2.3 Loading in Chunks:\n",
    "\n",
    "- We will attempt to read dataframe in chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c07eb0-bf10-4175-80c0-744af2d814f8",
   "metadata": {},
   "source": [
    "#### Chunksize = 10 million:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "172e7a9f-6edb-424b-8e66-e6f0389336c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "AWI-ESM-1-1-LR       966420\n",
      "BCC-CSM2-MR         3035340\n",
      "BCC-ESM1             551880\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "CanESM5              551880\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "FGOALS-f3-L         3219300\n",
      "FGOALS-g3           1287720\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "MIROC6              2070900\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-HR       5154240\n",
      "MPI-ESM1-2-LR        966420\n",
      "MRI-ESM2-0          3037320\n",
      "NESM3                966420\n",
      "NorESM2-LM           919800\n",
      "NorESM2-MM          3541230\n",
      "SAM0-UNICON         3541153\n",
      "TaiESM1             3541230\n",
      "dtype: int64\n",
      "peak memory: 2729.70 MiB, increment: 1497.36 MiB\n",
      "CPU times: user 1min 6s, sys: 11.6 s, total: 1min 17s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "counts = pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(\"rainfall/combined_data.csv\", chunksize=10_000_000):\n",
    "    counts = counts.add(chunk[\"model\"].value_counts(), fill_value=0)\n",
    "print(counts.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b3342-3ebc-4e5a-a0ad-63b229547c75",
   "metadata": {},
   "source": [
    "#### Chunksize = 1 million:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a37c04e-9ffb-4e8a-80e2-0212bf7b391c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "AWI-ESM-1-1-LR       966420\n",
      "BCC-CSM2-MR         3035340\n",
      "BCC-ESM1             551880\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "CanESM5              551880\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "FGOALS-f3-L         3219300\n",
      "FGOALS-g3           1287720\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "MIROC6              2070900\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-HR       5154240\n",
      "MPI-ESM1-2-LR        966420\n",
      "MRI-ESM2-0          3037320\n",
      "NESM3                966420\n",
      "NorESM2-LM           919800\n",
      "NorESM2-MM          3541230\n",
      "SAM0-UNICON         3541153\n",
      "TaiESM1             3541230\n",
      "dtype: int64\n",
      "peak memory: 1303.84 MiB, increment: 158.27 MiB\n",
      "CPU times: user 1min 4s, sys: 9.08 s, total: 1min 13s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "counts = pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(\"rainfall/combined_data.csv\", chunksize=1_000_000):\n",
    "    counts = counts.add(chunk[\"model\"].value_counts(), fill_value=0)\n",
    "print(counts.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a142457-13db-45a4-9e49-26533081af6b",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "> When loading the data in chunks, the peak memory is significantly lower than that without using chunking method. We can see that loading in 10 million per chunk requires nearly 6800 MiB in peak memory usage, which is less than using Pandas to load all at once. Loading in 1 million per chunk requires only 3740 MiB in peak memory usage. The increment memory is almost 10 times less than using Pandas. This is significantly more efficient than using Pandas. However, we also notice that the CPU and wall time remains roughly the same in all these approaches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ca15d3-ce53-4422-9e26-7b505275ffe7",
   "metadata": {},
   "source": [
    "### 5.2.4 Selecting columns:\n",
    "\n",
    "Since we only want the model for EDA, we will import just the model column. This is faster and uses less memory than loading the whole dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c559aba-0717-48f7-bc1f-81ae8c4c0806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1962.19 MiB, increment: 951.45 MiB\n",
      "CPU times: user 26.1 s, sys: 1.85 s, total: 28 s\n",
      "Wall time: 29.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df = pd.read_csv(\"rainfall/combined_data.csv\", \n",
    "                 usecols = [\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f323be2a-c344-4b9b-86c0-6b5ffd7b5f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1484.82 MiB, increment: 0.21 MiB\n",
      "CPU times: user 3.55 s, sys: 64.7 ms, total: 3.61 s\n",
      "Wall time: 4.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df[\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c24e81-a7da-478f-bf35-987c6cf57509",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    ">Running value_counts takes the same time as it did using the entire data set, probably because it has to iterate through the same number of rows. However, this should still be done whenever possible because it reduces memory required and speeds up loading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2afa840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7f85dfb",
   "metadata": {},
   "source": [
    "## 5.3 Summary\n",
    "\n",
    "### 5.3.1 Summary of different approaches in terms of memory usage and execution time on one machine (Macbook Pro):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a001bdd4",
   "metadata": {},
   "source": [
    "| Approach                    | Peak Memory Usage (MB)     | Execution Wall Time | \n",
    "| ----------------------------| -------------------------- |---------------------| \n",
    "| Baseline                    |        7451.22 MiB         |        1min 36s     |\n",
    "| Change dtype to float32     |        4715.13 MiB         |        1min 43s     |   \n",
    "| Dask                        |        3904.75 MiB         |        23.2s        | \n",
    "| Load in chunks 10 millions  |        2729.70 MiB         |        1min 20s     |   \n",
    "| Load in chunks 1 million    |        1303.84 MiB         |        1min 15s     | \n",
    "| Select single column        |        1484.8 MiB          |        4.17s        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df175507-1daa-4a69-bdd8-2ac35b08f685",
   "metadata": {},
   "source": [
    "- In terms of memory usage, loading in chunks of 1 million and selecting single column of interest shows the best performance.\n",
    "\n",
    "- In terms of execution time, using a single column is the fastest followed by Dask. Both methods are much faster than the Baseline and other methods had similar time performance as baseline.\n",
    "\n",
    "- To summarize, if analysis does not involve many columns of the dataset, we could consider using the single column of interest to achieve the best memory and time performance. If more than 1 column is required in the analysis, we would consider using Dask with a reasonable memory usage and a fast execution time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f9666a",
   "metadata": {},
   "source": [
    "### 5.3.2 Comparison of different machines on two approaches - changing data type and using Dask:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f1f477",
   "metadata": {},
   "source": [
    "| Team Member | Operating System     | RAM       | Processor                                                     | Is SSD   | Time Taken (changing dtype to float32) | Time Taken (Dask) |\n",
    "| ----------- | -----------          |-----------| ---------- ---------------------------------------------------|----------|---------  --------------|  --------------      |\n",
    "| Jessie      | Windows 10 Education |  16GB      |   Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz   1.99 GHz        |   Yes    |  peak memory: 8487.61 MiB, increment: 2461.12 MiB <br> CPU times: total: 1min 44s <br> Wall time: 1min 46s   |  peak memory: 4749.06 MiB, increment: 1255.98 MiB <br> CPU times: total: 1min 8s <br> Wall time: 23.5s  | \n",
    "| Adrianne    | Windows 10 Pro       |  16GB     | Intel(R) Core(TM) i7-1165G7 @ 2.80GHz 2.80 GHz                |   Yes     | peak memory: 13214.80 MiB, increment: 9233.91 MiB <br> CPU times: total: 55.4s <br> Wall time: 57s           | peak memory: 4240.98 MiB, increment: 1255.65 MiB <br> CPU times: total: 57.2s <br> Wall time: 20.6s  |\n",
    "| Rada        | Macbook Pro 2013 15\" |  16GB     | 2.3 GHz Intel Core i7                                         |   No      | peak memory: 4715.13 MiB, increment: 1308.29 MiB <br> CPU times: user 1min 9s, sys: 24.7 s, total: 1min 34s <br> Wall time: 1min 43s   | peak memory: 3904.75 MiB, increment: 1306.16 MiB <br> CPU times: user 49.2 s, sys: 13.4 s, total: 1min 2s <br> Wall time: 23.2 s\n",
    "| Moid        |                      |           |                                                                |           |           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad2ac68-c355-45c4-a42f-456082879e82",
   "metadata": {},
   "source": [
    "# 6. Perform a simple EDA in R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d556d66-1dd5-4594-b1c8-3bcf015c9c52",
   "metadata": {},
   "source": [
    "To perform EDA in R, we first need to transfer the dataframe from Python to R.\n",
    "In this section, we will pass data from python to R in various ways and asses each method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4b97ee-224d-4711-81a6-6d224ca8ea26",
   "metadata": {},
   "source": [
    "## 6.1 Store the Data in Different Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d22021-6d55-41b9-93c6-6b3434250e4c",
   "metadata": {},
   "source": [
    "### 6.1.1 Arrow file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1791571a-601c-4c65-80da-f4f53109350d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "Attaching package: dplyr\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from package:stats:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from package:base:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "#Loading library\n",
    "library(arrow);\n",
    "library(dplyr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ae424c3-dabe-45cf-9c61-fe4fe8090c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3466.32 MiB, increment: 1859.34 MiB\n",
      "CPU times: user 23.6 s, sys: 4.62 s, total: 28.2 s\n",
      "Wall time: 26.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "dataset = ds.dataset(\"rainfall/combined_data.csv\", format=\"csv\")\n",
    "\n",
    "table = dataset.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d002a84-b8c0-470f-8cbc-4346c09aaffe",
   "metadata": {},
   "source": [
    "### 6.1.2 Feather format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cef5510f-b285-4951-9769-8a97e70a732e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.4 s, sys: 17.7 s, total: 23.1 s\n",
      "Wall time: 7.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "feather.write_feather(table, 'rainfall/combined_data.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdd7906-6bce-4341-86e9-cc4c5d8829e1",
   "metadata": {},
   "source": [
    "> Feather format comes with over 3x Wall time improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796ee1cc-5937-4896-8814-c698bcf9a5f2",
   "metadata": {},
   "source": [
    "### 6.1.2 Parquet format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa622966-5564-423e-be5e-707217d6ceb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 s, sys: 365 ms, total: 10.9 s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## writing as a single parquet \n",
    "pq.write_table(table, 'rainfall/combined_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc188151-37fd-41b1-be87-af95099f6da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.7 s, sys: 14.4 s, total: 39.1 s\n",
      "Wall time: 35.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## writing as a partitioned parquet \n",
    "pq.write_to_dataset(table, 'rainfall/combined_data_partitioned.parquet',partition_cols=['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff29c01a-417e-4d25-b196-bfdda24e996d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.6G\trainfall/combined_data.csv\n",
      "1.0G\trainfall/combined_data.feather\n",
      "544M\trainfall/combined_data.parquet\n",
      "548M\trainfall/combined_data_partitioned.parquet\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# Check the size of different format\n",
    "du -sh rainfall/combined_data.csv\n",
    "du -sh rainfall/combined_data.feather\n",
    "du -sh rainfall/combined_data.parquet\n",
    "du -sh rainfall/combined_data_partitioned.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd0a49f-fbcb-4646-bb6d-b9e53e234537",
   "metadata": {},
   "source": [
    ">We can see that both Feather and Parquet have reduced the file size significantly. The wall time taken for feather and single parquet was much less than Arrow. Partitioned parquet took similar wall time as Arrow but it significantly reduced the file size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d620597d-5093-4c5d-9895-9bab9266d5fb",
   "metadata": {},
   "source": [
    "## 6.2 Transfer the Data in Different Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2e2f6f-dbba-43b1-bcb3-7ae12143d504",
   "metadata": {},
   "source": [
    "### 6.2.1 Pandas Exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eebae683-f571-4708-9401-61e628c46c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 7035.93 MiB, increment: 6672.44 MiB\n",
      "CPU times: user 1min 3s, sys: 19.9 s, total: 1min 23s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "#simple pandas: read the entire dataset into memory\n",
    "df = pd.read_csv(\"rainfall/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba032d9e-3269-4101-a14c-ce078a8669d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R -i df\n",
    "start_time <- Sys.time()\n",
    "library(dplyr)\n",
    "# print(class(df))\n",
    "result <- df |> count(model)\n",
    "#print(result)\n",
    "end_time <- Sys.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fa6945-4694-4e20-9a7d-1af44571a4e3",
   "metadata": {},
   "source": [
    "### 6.2.2 Arrow Exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2571cb4-591b-4193-8045-cc417f952035",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "dataset = ds.dataset(\"rainfall/combined_data.csv\", format=\"csv\")\n",
    "table = dataset.to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e1e2c5-1b37-4672-bce9-2dcd5235e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "## Here we are converting arrow table so it can be passed to R\n",
    "r_table = pyra.converter.py2rpy(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31674021-c79c-4592-acb7-1af67a2e1361",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R -i r_table\n",
    "# Pass r_table from python\n",
    "\n",
    "start_time <- Sys.time()\n",
    "library(dplyr)\n",
    "counts <- r_table %>% collect() %>% count(model)\n",
    "end_time <- Sys.time()\n",
    "\n",
    "print(counts)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca4a476-55b9-4baa-9606-03f42fccac6a",
   "metadata": {},
   "source": [
    "### 6.2.3 Feather File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d04fcff-5bb6-491e-8534-523d7007818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "library(arrow)\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_feather(\"rainfall/combined_data.feather\")\n",
    "print(class(r_table))\n",
    "library(dplyr)\n",
    "result <- r_table %>% count(model) \n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb8ff2b-fab0-4cdb-890c-dc3112349d0c",
   "metadata": {},
   "source": [
    "### 6.2.4 Parquet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151b0d7-28d6-4303-9fad-c92ee8b46050",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "library(arrow)\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_parquet(\"rainfall/combined_data.parquet\")\n",
    "print(class(r_table))\n",
    "library(dplyr)\n",
    "result <- r_table %>% count(model)\n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a698807-c796-4212-8a99-23f6252f9eda",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295d73d4-1ab3-4cb1-9663-5c6683eb98af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525_2022]",
   "language": "python",
   "name": "conda-env-525_2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
