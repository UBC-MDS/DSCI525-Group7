{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b854f4ee-3a3c-4273-8c32-9cbe4aa4546a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64811e1-9064-4578-9ab0-bef2d10afd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# pyarrow and feather\n",
    "import pyarrow.feather as feather\n",
    "import pyarrow.dataset as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "933642a1-e811-4fdc-a613-26f675f22ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jessie\\miniconda3\\envs\\525_2022\\lib\\site-packages\\rpy2\\robjects\\packages.py:366: UserWarning: The symbol 'quartz' is not in this R namespace/package.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5976a30-5808-477f-abb2-cc4a464ca8a4",
   "metadata": {},
   "source": [
    "# 1. Teamwork Contract\n",
    "The teamwork contract for our team, group 7, can be found [here](https://docs.google.com/document/d/1u4e5Z5C-uwTTSvCEyOYy-I30Fb8OEPYM6frM0NBEVVc/edit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9aee01-4eb9-4a7b-8920-802d235f9199",
   "metadata": {},
   "source": [
    "# 2. Create repository and project structure\n",
    "The repository URL: https://github.com/UBC-MDS/DSCI525-Group7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e53d5d4-a952-4b38-84cf-7b96510045c4",
   "metadata": {},
   "source": [
    "# 3. Downloading the data\n",
    "\n",
    "Using Python **requests** Library\n",
    "\n",
    "We are using article id #14096681, which contains the data of **Daily rainfall over NSW, Australia.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c326b50-df61-4679-b95c-7c5e18cc9a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "article_id = 14096681  \n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"rainfall/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de6fe8-cef7-4184-94c6-82f29e2cfd42",
   "metadata": {},
   "source": [
    "Review the files within the article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e03159ea-764b-46fc-8a20-249e5529894b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 26579150,\n",
       "  'name': 'daily_rainfall_2014.png',\n",
       "  'size': 58863,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579150',\n",
       "  'supplied_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'computed_md5': 'fd32a2ffde300a31f8d63b1825d47e5e'},\n",
       " {'id': 26579171,\n",
       "  'name': 'environment.yml',\n",
       "  'size': 192,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579171',\n",
       "  'supplied_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'computed_md5': '060b2020017eed93a1ee7dd8c65b2f34'},\n",
       " {'id': 26586554,\n",
       "  'name': 'README.md',\n",
       "  'size': 5422,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26586554',\n",
       "  'supplied_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'computed_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c'},\n",
       " {'id': 26766812,\n",
       "  'name': 'data.zip',\n",
       "  'size': 814041183,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766812',\n",
       "  'supplied_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'computed_md5': 'b517383f76e77bd03755a63a8ff83ee9'},\n",
       " {'id': 26766815,\n",
       "  'name': 'get_data.py',\n",
       "  'size': 4113,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766815',\n",
       "  'supplied_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'computed_md5': '7829028495fd9dec9680ea013474afa6'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # this contains all the articles data, feel free to check it out\n",
    "files = data[\"files\"]             # this is just the data about the files, which is what we want\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e52d215-05c2-48a4-834b-4e1f71890473",
   "metadata": {},
   "source": [
    "# 3.1 Unzipping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c5cf54-861a-4e80-8a72-cdfdaca747ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.48 s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "files_to_dl = [\"data.zip\"]  \n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a659d0f5-fbce-4e61-8c93-dba0e36e82a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(os.path.join(output_directory, \"data.zip\"), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62750636-4ddb-4e19-a4d2-bab89e561242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid switch - \"\".\n"
     ]
    }
   ],
   "source": [
    "%ls -ltr rainfall/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b56f5-8d99-4085-aa8f-bcc95b6a6c40",
   "metadata": {},
   "source": [
    "# Comparison of Performance on Different Machines\n",
    "\n",
    "The summary of all team members' time taken to unzip the data is recorded below. Each team member's Operating System, RAM, Processor and SSD are also recorded to check if they have any effect on the time taken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd7aa16-f118-4b18-b1a7-bdcadb5f505a",
   "metadata": {},
   "source": [
    "| Team Member | Operating System     | RAM       | Processor                                                      | Is SSD   | Time Taken |\n",
    "| ----------- | -----------          |-----------| ---------- ---------------------------------------------------|----------|---------  -|\n",
    "| Jessie      | Windows 10 Education |  16GB      |   Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz   1.99 GHz        |   Yes    |  CPU times: total: 8.48 s <br> Wall time: 1min 35s          |\n",
    "| Adrianne    |                      |           |                                                               |           |           |\n",
    "| Rada        |                      |           |                                                               |           |           |\n",
    "| Moid        |                      |           |                                                                |           |           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6ba519-2c6d-4224-8531-2e7167833810",
   "metadata": {},
   "source": [
    ">**Discussion of results above**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96637ec-45ec-404a-831e-1c370d6a6439",
   "metadata": {},
   "source": [
    "# 4. Combining data CSVs\n",
    "\n",
    "- Combine data CSVs into a single CSV using pandas.\n",
    "\n",
    "- When combining the CSV files, add an extra column called \"model\" that identifies the model. Tip 1: you can get this column populated from the file name, eg: for file name \"SAM0-UNICON_daily_rainfall_NSW.csv\", the model name is SAM0-UNICON Tip 2: Remember how we added year when we combined airline CSVs. Tip 3: You can use regex generator.\n",
    "\n",
    "_Note: There is a file called observed_daily_rainfall_SYD.csv in the data folder that you downloaded. Make sure you exclude this file (programmatically or just take out that file from folder) before you combine CSVs. We will use this file in our next milestone._\n",
    "\n",
    "- Compare run times on different machines within your team and summarize your observations.\n",
    "Warning: Some of you might not be able to do it on your laptop. It's fine if you're unable to do it. Just make sure you discuss the reasons why you might not have been able to run this on your laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40676871-8964-4489-a541-0e84a7ac149c",
   "metadata": {},
   "source": [
    "Let's first view the data and the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf991be5-9a08-43ac-b12e-708d81bdc456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7.16 s\n",
      "Wall time: 7.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_1 = pd.read_csv(output_directory+\"/MPI-ESM-1-2-HAM_daily_rainfall_NSW.csv\")\n",
    "df_2 = pd.read_csv(output_directory+\"/CMCC-CM2-SR5_daily_rainfall_NSW.csv\")\n",
    "df_3 = pd.read_csv(output_directory+\"/SAM0-UNICON_daily_rainfall_NSW.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e69142-a3fc-4b6f-81ad-b45a666263ef",
   "metadata": {},
   "source": [
    "Even loading three of the individual files is taking a little time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cd74e93-83bc-45bd-9376-135b045e5702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.244226e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.217326e-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time    lat_min    lat_max   lon_min   lon_max  \\\n",
       "0  1889-01-01 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "1  1889-01-02 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "\n",
       "   rain (mm/day)  \n",
       "0   4.244226e-13  \n",
       "1   4.217326e-13  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d56f6df-a1e0-494b-9c28-916ad97e95ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>0.000424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>0.006158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time    lat_min   lat_max  lon_min  lon_max  rain (mm/day)\n",
       "0  1889-01-01 12:00:00 -35.811518 -34.86911  140.625  141.875       0.000424\n",
       "1  1889-01-02 12:00:00 -35.811518 -34.86911  140.625  141.875       0.006158"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7be8e1b4-58a5-4a0d-9044-9d358566f661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>3.045650e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>3.572392e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time    lat_min   lat_max  lon_min  lon_max  rain (mm/day)\n",
       "0  1889-01-01 12:00:00 -35.811518 -34.86911  140.625  141.875   3.045650e-13\n",
       "1  1889-01-02 12:00:00 -35.811518 -34.86911  140.625  141.875   3.572392e-04"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f49d1b94-dccd-4427-a814-081554396930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3541151</th>\n",
       "      <td>2014-12-30 12:00:00</td>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>8.541592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541152</th>\n",
       "      <td>2014-12-31 12:00:00</td>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>68.117489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time    lat_min   lat_max  lon_min  lon_max  \\\n",
       "3541151  2014-12-30 12:00:00 -30.157068 -29.21466  153.125  154.375   \n",
       "3541152  2014-12-31 12:00:00 -30.157068 -29.21466  153.125  154.375   \n",
       "\n",
       "         rain (mm/day)  \n",
       "3541151       8.541592  \n",
       "3541152      68.117489  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f9e0468-45da-419a-94dc-f0b576a9ed11",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:2\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\525_2022\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\525_2022\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:346\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[0;32m    144\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[Hashable, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    153\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    154\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m    along the other axes.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;124;03m    ValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\525_2022\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:400\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    398\u001b[0m     objs \u001b[38;5;241m=\u001b[39m [objs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys]\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 400\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m<timed exec>:3\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "files = glob.glob('rainfall/*NSW.csv')\n",
    "df = pd.concat((pd.read_csv(file, index_col=0)\n",
    "                .assign(model=re.findall(r'/([^_]*)', file)[0])\n",
    "                for file in files)\n",
    "              )\n",
    "df.to_csv(\"rainfall/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50c64f81-752f-4c2d-80bc-a3b224980550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Windows user \n",
    "##  Windows users will run into an index error when running the code above to combine the CSVs. This can be solved by adding a ./ to the filename as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18b7f1d9-b89d-4ae3-b3d4-6460016748a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 800.19 MiB, increment: 0.00 MiB\n",
      "CPU times: total: 8min 45s\n",
      "Wall time: 8min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "files = glob.glob('./rainfall/*NSW.csv')\n",
    "df = pd.concat((pd.read_csv(file, index_col=0)\n",
    "                .assign(model=file.strip('./rainfall\\\\').split('_')[0])\n",
    "                for file in files)\n",
    "              )\n",
    "df.to_csv(\"rainfall/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd16d5f7-77a6-4bcf-9cd7-98505b2a983c",
   "metadata": {},
   "source": [
    "Wow, this felt like an eternity!\n",
    "\n",
    "Let's take a look at the combined file, see if head and tail are as we expect them to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bab6c92a-e605-4b11-b7d6-472e73a691cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1889-01-01 12:00:00</th>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>3.293256e-13</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-02 12:00:00</th>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-03 12:00:00</th>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-04 12:00:00</th>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-05 12:00:00</th>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.5</td>\n",
       "      <td>1.047658e-02</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     lat_min  lat_max  lon_min  lon_max  rain (mm/day)  \\\n",
       "time                                                                     \n",
       "1889-01-01 12:00:00   -36.25    -35.0  140.625    142.5   3.293256e-13   \n",
       "1889-01-02 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "1889-01-03 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "1889-01-04 12:00:00   -36.25    -35.0  140.625    142.5   0.000000e+00   \n",
       "1889-01-05 12:00:00   -36.25    -35.0  140.625    142.5   1.047658e-02   \n",
       "\n",
       "                          model  \n",
       "time                             \n",
       "1889-01-01 12:00:00  ACCESS-CM2  \n",
       "1889-01-02 12:00:00  ACCESS-CM2  \n",
       "1889-01-03 12:00:00  ACCESS-CM2  \n",
       "1889-01-04 12:00:00  ACCESS-CM2  \n",
       "1889-01-05 12:00:00  ACCESS-CM2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2635431e-cbf1-4056-8638-4aa81ccc4987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-27 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>0.554375</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-28 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>7.028577</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-29 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>0.234757</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>2.097459</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 12:00:00</th>\n",
       "      <td>-30.157068</td>\n",
       "      <td>-29.21466</td>\n",
       "      <td>153.125</td>\n",
       "      <td>154.375</td>\n",
       "      <td>0.548421</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       lat_min   lat_max  lon_min  lon_max  rain (mm/day)  \\\n",
       "time                                                                        \n",
       "2014-12-27 12:00:00 -30.157068 -29.21466  153.125  154.375       0.554375   \n",
       "2014-12-28 12:00:00 -30.157068 -29.21466  153.125  154.375       7.028577   \n",
       "2014-12-29 12:00:00 -30.157068 -29.21466  153.125  154.375       0.234757   \n",
       "2014-12-30 12:00:00 -30.157068 -29.21466  153.125  154.375       2.097459   \n",
       "2014-12-31 12:00:00 -30.157068 -29.21466  153.125  154.375       0.548421   \n",
       "\n",
       "                       model  \n",
       "time                          \n",
       "2014-12-27 12:00:00  TaiESM1  \n",
       "2014-12-28 12:00:00  TaiESM1  \n",
       "2014-12-29 12:00:00  TaiESM1  \n",
       "2014-12-30 12:00:00  TaiESM1  \n",
       "2014-12-31 12:00:00  TaiESM1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41611d5-c775-43c5-9422-4df1ddbd0333",
   "metadata": {},
   "source": [
    "## Comparison of Performance on Different Machines\n",
    "\n",
    "The summary of all team members' time taken to combine the CSV's files is recorded below. Each team member's Operating System, RAM, Processor and SSD are also recorded to check if they have any effect on the time taken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4cc9f7-345e-4c9c-90b5-ecd922fea905",
   "metadata": {},
   "source": [
    "| Team Member | Operating System     | RAM       | Processor                                                      | Is SSD   | Time Taken |\n",
    "| ----------- | -----------          |-----------| ---------- ---------------------------------------------------|----------|---------  -|\n",
    "| Jessie      | Windows 10 Education |  16GB      |   Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz   1.99 GHz        |   Yes    |  peak memory: 800.19 MiB  increment: 0.00 MiB <br> CPU times: total: 8min 33s <br> Wall time: 8min 40s          |\n",
    "| Adrianne    |                      |           |                                                               |           |           |\n",
    "| Rada        |                      |           |                                                               |           |           |\n",
    "| Moid        |                      |           |                                                                |           |           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7940f07a-90db-4d37-b0e2-b81309929f48",
   "metadata": {},
   "source": [
    "> **Discussion of results above** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b7fbb1-e064-4862-bfd7-366e4810b3e3",
   "metadata": {},
   "source": [
    "# 5. Load the combined CSV to memory and perform a simple EDA\n",
    "\n",
    "1. Investigate at least two of the following approaches to reduce memory usage while performing the EDA (e.g., value_counts).\n",
    "\n",
    "- Changing dtype of your data\n",
    "- Load just columns what we want\n",
    "- Loading in chunks\n",
    "- Dask\n",
    "\n",
    "2. Compare run times on different machines within your team and summarize your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01927b22-3abf-4ddd-b972-1391b3067bb1",
   "metadata": {},
   "source": [
    "**The EDA will be to use value_counts() to count the number of data points that came from each .csv file, as recorded in the model column of combined_data.csv.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16642faa-44e6-4a8b-bb6e-2aafe730d977",
   "metadata": {},
   "source": [
    "### 5.1 Load the Entire Dataframe to Memory Using Pandas (Baseline for Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b38fd63-c051-4f6a-9a54-ba7a66b7185a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "TaiESM1             3541230\n",
      "NorESM2-MM          3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "SAM0-UNICON         3541153\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "MRI-ESM2-0          3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM5-0           1609650\n",
      "INM-CM4-8           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "Name: model, dtype: int64\n",
      "peak memory: 9060.10 MiB, increment: 4510.68 MiB\n",
      "CPU times: total: 1min 28s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "df_pandas = pd.read_csv(\"rainfall/combined_data.csv\")\n",
    "print(df_pandas[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382ea113-f801-4c4c-ab36-f979c902ca79",
   "metadata": {},
   "source": [
    "**Observations**\n",
    ">Our baseline approach is to use Pandas to load the entire data to memory. The above code loads the combined_data.csv to memory and performs a simple EDA to calculate counts of values in the \"model\" column. We see that the peak memory is 9060 MiB and the CPU and wall time is 1min 31s. We will explore some other approaches to see if we can reduce the time and memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e74ea-8f2a-4748-ab28-9e704e8d89b6",
   "metadata": {},
   "source": [
    "### 5.2 Changing dtypes of data:\n",
    "\n",
    "- We will attempt to change time column from datetime to date\n",
    "- We will attempt to read the numerical columns using float32 format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c78aef6-e83a-44d2-9619-75d946e92a58",
   "metadata": {},
   "source": [
    "Memory comparison for format changes adapted from Lecture notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f52fc-640e-4e20-9826-721f5fefc3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9bb9533-b591-4e30-9f96-12c7ae5a4a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage with float64: 2998.46 MB\n",
      "Memory usage with float32: 1749.10 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory usage with float64: {df[['lat_min','lat_max', 'lon_min', 'lon_max', 'rain (mm/day)']].memory_usage().sum() / 1e6:.2f} MB\")\n",
    "print(f\"Memory usage with float32: {df[['lat_min','lat_max', 'lon_min', 'lon_max', 'rain (mm/day)']].astype('float32', errors='ignore').memory_usage().sum() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8666e81b-c151-4de1-be4a-8f05e419da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_float32 = df.copy()\n",
    "df_float32[['lat_min','lat_max','lon_min', 'lon_max', 'rain (mm/day)']].astype('float32')\n",
    "\n",
    "#saving the dataframe of float32 to file\n",
    "df_float32.to_csv(\"rainfall/combined_data_float32.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e243f1be-cee8-48a8-a455-bc9c051f4a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "#loading the float32 dataframe to memory and perform a simple EDA for value counts of model column\n",
    "df_float32 = pd.read_csv(\"rainfall/combined_data_float32.csv\")\n",
    "print(df_float32[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae86de81-2d49-49c3-817c-41a28ec5a3f2",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "> When we changed the data type from float64 to float32 the memory usage reduced by nearly half. This is because float32 is stored as a 32-bit number, while float64 is stored as 64-bit number, which is twice as much memory as float32. With the EDA, we see that after converting dtypes to float 32, the peak memory usage decreased to and both CPU and wall time in/decreased.Changing the dtype is effective in reducing the time and memory required to load data, and should be used when we have a large amount of data that does not require very high precision.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f5c3d-f616-4cc2-a908-50aa9b72055e",
   "metadata": {},
   "source": [
    "### 5.3 Dask:\n",
    "\n",
    "- We will attempt to read dataframe using dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8bdeaff-ec09-4819-a7c2-db4deeda9e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "TaiESM1             3541230\n",
      "NorESM2-MM          3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "SAM0-UNICON         3541153\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "MRI-ESM2-0          3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM5-0           1609650\n",
      "INM-CM4-8           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "Name: model, dtype: int64\n",
      "peak memory: 4749.06 MiB, increment: 1255.98 MiB\n",
      "CPU times: total: 1min 8s\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "%%memit\n",
    "# Dask\n",
    "df_dask = dd.read_csv('rainfall/combined_data.csv')\n",
    "print(df_dask[\"model\"].value_counts().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432e8485-ede7-4179-b7b2-3fee5b49fa00",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "> Using a Dask dataframe is much faster and lighter on memory. Compared to loading the csv to pandas data frame, when we load the csv file to dask, the peak memory, increment memory, and wall time all reduced significantly when calling the value_counts() function. This is likely because dask partitioned the dataframe based on row index and did the calculation in parallel to improve the efficiency. Thus, for large-scale data calculation, we could use dask instead of pandas to improve the code efficiency with minimal syntax change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bec6a11-a1c7-47b4-a86f-a44603bd07f2",
   "metadata": {},
   "source": [
    "### 5.4 Loading in Chunks:\n",
    "\n",
    "- We will attempt to read dataframe in chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c07eb0-bf10-4175-80c0-744af2d814f8",
   "metadata": {},
   "source": [
    "#### Chunksize = 10 million:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "172e7a9f-6edb-424b-8e66-e6f0389336c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "AWI-ESM-1-1-LR       966420\n",
      "BCC-CSM2-MR         3035340\n",
      "BCC-ESM1             551880\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "CanESM5              551880\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "FGOALS-f3-L         3219300\n",
      "FGOALS-g3           1287720\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "MIROC6              2070900\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-HR       5154240\n",
      "MPI-ESM1-2-LR        966420\n",
      "MRI-ESM2-0          3037320\n",
      "NESM3                966420\n",
      "NorESM2-LM           919800\n",
      "NorESM2-MM          3541230\n",
      "SAM0-UNICON         3541153\n",
      "TaiESM1             3541230\n",
      "dtype: int32\n",
      "peak memory: 6795.32 MiB, increment: 2462.11 MiB\n",
      "CPU times: total: 1min 14s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "counts = pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(\"rainfall/combined_data.csv\", chunksize=10_000_000):\n",
    "    counts = counts.add(chunk[\"model\"].value_counts(), fill_value=0)\n",
    "print(counts.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b3342-3ebc-4e5a-a0ad-63b229547c75",
   "metadata": {},
   "source": [
    "#### Chunksize = 1 million:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a37c04e-9ffb-4e8a-80e2-0212bf7b391c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "AWI-ESM-1-1-LR       966420\n",
      "BCC-CSM2-MR         3035340\n",
      "BCC-ESM1             551880\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "CanESM5              551880\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "FGOALS-f3-L         3219300\n",
      "FGOALS-g3           1287720\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "MIROC6              2070900\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-HR       5154240\n",
      "MPI-ESM1-2-LR        966420\n",
      "MRI-ESM2-0          3037320\n",
      "NESM3                966420\n",
      "NorESM2-LM           919800\n",
      "NorESM2-MM          3541230\n",
      "SAM0-UNICON         3541153\n",
      "TaiESM1             3541230\n",
      "dtype: int32\n",
      "peak memory: 3741.75 MiB, increment: 254.97 MiB\n",
      "CPU times: total: 1min 22s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "counts = pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(\"rainfall/combined_data.csv\", chunksize=1_000_000):\n",
    "    counts = counts.add(chunk[\"model\"].value_counts(), fill_value=0)\n",
    "print(counts.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a142457-13db-45a4-9e49-26533081af6b",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "> When loading the data in chunks, the peak memory is significantly lower than that without using chunking method. We can see that loading in 10 million per chunk requires nearly 6800 MiB in peak memory usage, which is less than using Pandas to load all at once. Loading in 1 million per chunk requires only 4,235 MiB in peak memory usage. This is significantly more efficient than using Pandas. However, we also notice that the CPU and wall time remains roughly the same in all these approaches.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ca15d3-ce53-4422-9e26-7b505275ffe7",
   "metadata": {},
   "source": [
    "### 5.5 Selecting columns:\n",
    "\n",
    "Since we only want the model for EDA, we will import just the model column. This is faster and uses less memory than loading the whole dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c559aba-0717-48f7-bc1f-81ae8c4c0806",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df = pd.read_csv(\"rainfall/combined_data.csv\", \n",
    "                 usecols = [\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f323be2a-c344-4b9b-86c0-6b5ffd7b5f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df[\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c24e81-a7da-478f-bf35-987c6cf57509",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    ">Running value_counts takes the same time as it did using the entire data set, probably because it has to iterate through the same number of rows. However, this should still be done whenever possible because it reduces memory required and speeds up loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad2ac68-c355-45c4-a42f-456082879e82",
   "metadata": {},
   "source": [
    "# 6. Perform a simple EDA in R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d556d66-1dd5-4594-b1c8-3bcf015c9c52",
   "metadata": {},
   "source": [
    "To perform EDA in R, we first need to transfer the dataframe from Python to R.\n",
    "In this section, we will pass data from python to R in various ways and asses each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7f98a1-6265-4b68-a5d7-7e59d07aa191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525_2022]",
   "language": "python",
   "name": "conda-env-525_2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
